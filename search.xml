<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>11.Scrapy爬虫基本使用及实例</title>
      <link href="2020/11/24/python-c-11/"/>
      <url>2020/11/24/python-c-11/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-XcCDEVxE" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="857896" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #6495ED"    ></div><p>&nbsp;</p><h1 id="Scrapy爬虫基本使用"><a href="#Scrapy爬虫基本使用" class="headerlink" title="Scrapy爬虫基本使用"></a><strong>Scrapy爬虫基本使用</strong></h1><h2 id="Scrapy爬虫的使用步骤"><a href="#Scrapy爬虫的使用步骤" class="headerlink" title="Scrapy爬虫的使用步骤"></a><strong>Scrapy爬虫的使用步骤</strong></h2><p>步骤1：创建一个工程和Spider模板</p><p>步骤2：编写Spider</p><p>步骤3：编写Item Pipeline</p><p>步骤4：优化配置策略</p><p>&nbsp;</p><h2 id="Scrapy爬虫的数据类型"><a href="#Scrapy爬虫的数据类型" class="headerlink" title="Scrapy爬虫的数据类型"></a><strong>Scrapy爬虫的数据类型</strong></h2><h3 id="Request类"><a href="#Request类" class="headerlink" title="Request类"></a><strong>Request类</strong></h3><p><code>class scrapy.http.Request()</code></p><ul><li>Request对象表示一个HTTP请求</li><li>由Spider生成，由Downloader执行</li></ul><table><thead><tr><th align="left">属性或方法</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.url</td><td align="left">Request对应的请求URL地址</td></tr><tr><td align="left">.method</td><td align="left">对应的请求方法，’GET’’POST’等</td></tr><tr><td align="left">.headers</td><td align="left">字典类型风格的请求头</td></tr><tr><td align="left">.body</td><td align="left">请求内容主体，字符串类型</td></tr><tr><td align="left">.meta</td><td align="left">用户添加的扩展信息，在Scrapy内部模块间传递信息使用</td></tr><tr><td align="left">.copy()</td><td align="left">复制该请求</td></tr></tbody></table><p>&nbsp;</p><h3 id="Reponse类"><a href="#Reponse类" class="headerlink" title="Reponse类"></a><strong>Reponse类</strong></h3><p><code>class scrapy.http.Response()</code></p><ul><li>Response对象表示一个HTTP响应</li><li>由Downloader生成，由Spider处理</li></ul><table><thead><tr><th align="left">属性或方法</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.url</td><td align="left">Response对应的URL地址</td></tr><tr><td align="left">.status</td><td align="left">HTTP状态码，默认是200</td></tr><tr><td align="left">.headers</td><td align="left">Response对应的头部信息</td></tr><tr><td align="left">.body</td><td align="left">Response对应的内容信息，字符串类型</td></tr><tr><td align="left">.flags</td><td align="left">一组标记</td></tr><tr><td align="left">.request</td><td align="left">产生Response类型对应的Request对象</td></tr><tr><td align="left">.copy</td><td align="left">复制该响应</td></tr></tbody></table><p>&nbsp;</p><h3 id="Item类"><a href="#Item类" class="headerlink" title="Item类"></a><strong>Item类</strong></h3><p><code>class scrapy.item.Item()</code></p><ul><li>Item对象表示一个从HTML页面中提取的信息内容</li><li>由Spider生成，由Item Pipeline处理</li><li>Item类似字典类型，可以按照字典类型操作</li></ul><p>&nbsp;</p><h2 id="Scrapy爬虫提取信息的方法"><a href="#Scrapy爬虫提取信息的方法" class="headerlink" title="Scrapy爬虫提取信息的方法"></a><strong>Scrapy爬虫提取信息的方法</strong></h2><ul><li>Beautiful Soup</li><li>lxml</li><li>re</li><li>XPath Selector</li><li>CSS Selector</li></ul><p>介绍一下陌生的<strong>CSS Selector</strong>，由<a href="https://baike.baidu.com/item/%E4%B8%87%E7%BB%B4%E7%BD%91%E8%81%94%E7%9B%9F/1458269?fromtitle=w3c&fromid=216888&fr=aladdin">W3C组织</a>维护并规范</p><p>基本使用格式<code>&lt;HTML&gt;.css(&#39;a::attr(href)&#39;).extract()</code></p><p>a为名称，href为属性</p><p>&nbsp;</p><h1 id="Scrapy爬虫实例"><a href="#Scrapy爬虫实例" class="headerlink" title="Scrapy爬虫实例"></a><strong>Scrapy爬虫实例</strong></h1><h2 id="演示HTML地址"><a href="#演示HTML地址" class="headerlink" title="演示HTML地址"></a><strong>演示HTML地址</strong></h2><p><code>http://python123.io/ws/demo.html</code></p><p>文件名称：demo.html</p><h2 id="产生步骤"><a href="#产生步骤" class="headerlink" title="产生步骤"></a><strong>产生步骤</strong></h2><h3 id="步骤1：建立一个Scrapy爬虫工程"><a href="#步骤1：建立一个Scrapy爬虫工程" class="headerlink" title="步骤1：建立一个Scrapy爬虫工程"></a><strong>步骤1：建立一个Scrapy爬虫工程</strong></h3><p>在cmd或者pycharm中输入<code>scrapy startproject python123demo</code></p><p>以python123demo定义一个工程目录名称，并会自动生成一系列文件</p><p>生成的工程目录</p><p>python123demo/     $\longrightarrow$     外层目录</p><p>scrapy.cfg                  $\longrightarrow$     <strong>部署</strong>（放在特定服务器，并配置好接口）Scrapy爬虫的配置文件</p><p>python123demo/     $\longrightarrow$     Scrapy框架用户自定义Python代码</p><p>_init_.py                      $\longrightarrow$     初始化脚本</p><p>items.py                     $\longrightarrow$     Items代码模板（继承类）</p><p>middlewares.py        $\longrightarrow$     Middlewares代码模块（继承类）</p><p>pipelines.py               $\longrightarrow$     Pipelines代码模板（继承类）</p><p>settings.py                 $\longrightarrow$     Scrapy爬虫的配置文件</p><p>spiders/                      $\longrightarrow$     Spiders代码模板目录（继承类）</p><p>&nbsp;</p><h3 id="步骤2：在工程中产生一个Scrapy爬虫"><a href="#步骤2：在工程中产生一个Scrapy爬虫" class="headerlink" title="步骤2：在工程中产生一个Scrapy爬虫"></a><strong>步骤2：在工程中产生一个Scrapy爬虫</strong></h3><p>在python123demo目录下输入命令<code>scrapy genspider demo python123.io</code>在spider目录下自动生成demo.py（也可手动）</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy<span class="token keyword">class</span> <span class="token class-name">DemoSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>    name <span class="token operator">=</span> <span class="token string">'demo'</span>    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'python123.io'</span><span class="token punctuation">]</span><span class="token comment">#用户提交给命令行的域名</span>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://python123.io/'</span><span class="token punctuation">]</span><span class="token comment">#所爬取的初始页面</span>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span></code></pre><p>parse()用于处理响应，解析内容形成字典，发现新的URL爬取请求。</p><p>&nbsp;</p><h3 id="步骤3：配置产生的spider爬虫"><a href="#步骤3：配置产生的spider爬虫" class="headerlink" title="步骤3：配置产生的spider爬虫"></a><strong>步骤3：配置产生的spider爬虫</strong></h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy<span class="token keyword">class</span> <span class="token class-name">DemoSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>    name <span class="token operator">=</span> <span class="token string">'demo'</span>    <span class="token comment">#allowed_domains = ['python123.io']</span>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://python123.io/ws/demo.html'</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname <span class="token operator">=</span> response<span class="token punctuation">.</span>url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fname<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>  <span class="token keyword">as</span> f<span class="token punctuation">:</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">'Save file %s.'</span> <span class="token operator">%</span> name<span class="token punctuation">)</span></code></pre><p>self是面向对象类所属关系的标记</p><p>response是从网页内容所存储或对应的对象</p><p>&nbsp;</p><h3 id="步骤4：运行爬虫，获取网页"><a href="#步骤4：运行爬虫，获取网页" class="headerlink" title="步骤4：运行爬虫，获取网页"></a><strong>步骤4：运行爬虫，获取网页</strong></h3><p>在python123demo目录下输入命令<code>scrapy crawl demo</code></p><p>可以看到页面文件被存储到python123demo目录下</p><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=54">参考资料</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.Scrapy爬虫框架</title>
      <link href="2020/11/19/python-c-10/"/>
      <url>2020/11/19/python-c-10/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-HbjGvtvH" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1343283719" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #6495ED"    ></div><p>&nbsp;</p><h1 id="Scrapy爬虫框架"><a href="#Scrapy爬虫框架" class="headerlink" title="Scrapy爬虫框架"></a><strong>Scrapy爬虫框架</strong></h1><p>爬虫框架</p><ul><li>爬虫框架是实现爬虫功能的一个软件结构和功能组件集合。</li><li>爬虫框架是一个半成品（需要补充），能够帮助用户实现专业网络爬虫。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/scrapy-kj.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><h2 id="Engine"><a href="#Engine" class="headerlink" title="Engine"></a>Engine</h2><ul><li>控制所有模块之间的数据流</li><li>根据条件触发事件</li><li>不需要用户修改</li></ul><p>&nbsp;</p><h2 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h2><ul><li>根据请求下载网页</li><li>不需要用户修改</li></ul><p>&nbsp;</p><h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><ul><li>对所有爬去请求进行调度管理</li><li>不需要用户修改</li></ul><p>因这三个模块不需要用户手动配置，Scrapy添加了一个中间件<strong>Downloader Middleware</strong>，可对这三个模块进行用户可配置的控制。</p><p>用户可通过编写该中间件进行修改、丢弃、新增请求或响应。</p><p>&nbsp;</p><h2 id="Spider（核心）"><a href="#Spider（核心）" class="headerlink" title="Spider（核心）"></a>Spider（核心）</h2><ul><li>解析Downloader返回的响应（Response）</li><li>产生爬取项（scrapyed item）</li><li>产生额外的爬取请求（Request）</li></ul><p>在spider与engine之间有个<strong>Spider Middleware</strong>，用以对请求和爬取项的再处理。</p><p>用户可通过编写该中间件进行修改、丢弃、新增请求或爬取项。</p><p>&nbsp;</p><h2 id="Item-Pipelines"><a href="#Item-Pipelines" class="headerlink" title="Item Pipelines"></a>Item Pipelines</h2><ul><li><p>以流水线方式处理Spider产生的爬取项</p></li><li><p>由一组操作顺序组成，类似流水线，每个操作是一个Item Pipeline类型</p></li><li><p>可能操作包括：清理、检验和查重爬取项中的HTML数据、将数据存储到数据库</p></li></ul><p>&nbsp;</p><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a><strong>常用命令</strong></h2><p>Scrapy命令行</p><p><code>&gt;scrapy&lt;command&gt;[options][args]</code></p><table><thead><tr><th align="left">命令</th><th align="left">说明</th><th>格式</th></tr></thead><tbody><tr><td align="left"><strong>startproject</strong></td><td align="left">创建一个新工程</td><td><code>scrapy startproject &lt;name&gt; [dir]</code></td></tr><tr><td align="left"><strong>genspider</strong></td><td align="left">创建一个爬虫</td><td><code>scrapy genspider [options] &lt;name&gt;&lt;domain&gt;</code></td></tr><tr><td align="left">settings</td><td align="left">获得爬虫配置信息</td><td><code>scrapy setting [options]</code></td></tr><tr><td align="left"><strong>crawl</strong></td><td align="left">运行一个爬虫</td><td><code>scrapy crawl &lt;spider&gt;</code></td></tr><tr><td align="left">list</td><td align="left">列出工程中所有爬虫</td><td><code>scrapy list</code></td></tr><tr><td align="left">shell</td><td align="left">启动URL调试命令行</td><td><code>scrapy shell [url]</code></td></tr></tbody></table><p>为啥Scrapy采用命令行创建和运行爬虫？</p><ul><li>命令行（不是图形界面）更容易自动化，适合脚本控制</li><li>本质上，Scrapy是给程序员用的，功能（不是界面）更重要</li></ul><p>&nbsp;</p><h1 id="与Request库的比较"><a href="#与Request库的比较" class="headerlink" title="与Request库的比较"></a><strong>与Request库的比较</strong></h1><p>相同点</p><ul><li>两者都可以进行页面请求和爬取，Python爬虫的两个重要技术路线</li><li>两者可用性都好，文档丰富，入门简单</li><li>两者都没有处理js、提交表单、应对验证码等功能（可扩展）</li></ul><table><thead><tr><th align="left">Requests</th><th align="left">Scrapy</th></tr></thead><tbody><tr><td align="left">页面级爬虫</td><td align="left">网站级爬虫</td></tr><tr><td align="left">功能库</td><td align="left">框架</td></tr><tr><td align="left">并发性考虑不足，性能较差</td><td align="left">并发性好，性能较高</td></tr><tr><td align="left">重点在于页面下载</td><td align="left">重点在于爬虫结构</td></tr><tr><td align="left">定制灵活</td><td align="left">一般定制灵活，深度定制困难</td></tr><tr><td align="left">上手十分简单</td><td align="left">入门稍难</td></tr></tbody></table><p>选用哪个技术路线开发爬虫？</p><ul><li>非常小的需求，Requests库</li><li>不太小的需求（想要形成自己的爬取库），Scrapy框架</li><li>定制程度很高的需求（不考虑规模），自搭框架，Requests &gt; Scrapy</li></ul><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=51">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/24/python-c-11">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.股票数据定向爬虫</title>
      <link href="2020/11/14/python-c-9/"/>
      <url>2020/11/14/python-c-9/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-fAocTVHu" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1341188360" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #6495ED"    ></div><p>&nbsp;</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a><strong>准备工作</strong></h1><p>目标：获取上交所和深交所所有股票的名称和交易信息。</p><p>输出：保存到文件中。</p><p>工具：requests-bs4-re</p><p>股票信息网站：</p><p>新浪股票：<a href="http://finance.sina.com.cn/stock/">http://finance.sina.com.cn/stock/</a></p><p>选取原则：股票信息静态存在与HTML页面中，非js代码生成，Robots协议限制。</p><p>在新浪股票中查看源代码，发现价格并不在源代码中，很可能是js代码生成的，换别的网站试试。</p><p>百度股票停止维护了，东方财富网的数据也在js中，最终找到几个适合爬取的网站</p><p>股城网：<a href="https://hq.gucheng.com/gpdmylb.html">https://hq.gucheng.com/gpdmylb.html</a></p><p>中财网：<a href="http://quote.cfi.cn/stockList.aspx">http://quote.cfi.cn/stockList.aspx</a></p><p>&nbsp;</p><p>可分为三个步骤</p><ol><li>获取股票列表getStockList()。</li><li>根据股票列表获取个股信息getStockInfo()。</li><li>将结果存储到文件。</li></ol><p>&nbsp;</p><h1 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a><strong>爬虫编写</strong></h1><p>以股城网为例：</p><pre class="language-none"><code class="language-none">import requestsfrom bs4 import BeautifulSoupimport rekv &#x3D; &#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;5.0&#39;&#125;def getHTMLText(url, code&#x3D;&#39;utf-8&#39;):    try:        r &#x3D; requests.get(url, headers&#x3D;kv, timeout&#x3D;30)        r.raise_for_status()        r.encoding &#x3D; code        return r.text    except:        return &quot;&quot;def getStockList(lst, stockURL):    html &#x3D; getHTMLText(stockURL)    soup &#x3D; BeautifulSoup(html, &#39;html.parser&#39;)    a &#x3D; soup.find_all(&#39;a&#39;)    for i in a:        try:            href &#x3D; i.attrs[&#39;href&#39;]            lst.append(re.findall(r&quot;[S][HZ]\d&#123;6&#125;&quot;, href)[0])        except:            continuedef getStockInfo(lst, stockURL, fpath):    count &#x3D; 0    for stock in lst:        url &#x3D; stockURL + stock        html &#x3D; getHTMLText(url)        try:            if html &#x3D;&#x3D; &quot;&quot;:                continue            infoDict &#x3D; &#123;&#125;            soup &#x3D; BeautifulSoup(html, &#39;html.parser&#39;)            stockInfo &#x3D; soup.find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;: &#39;stock_top clearfix&#39;&#125;)            name &#x3D; stockInfo.find_all(attrs&#x3D;&#123;&#39;class&#39;: &#39;stock_title&#39;&#125;)[0]            infoDict.update(&#123;&#39;股票名称&#39;: name.text.split()[0]&#125;)            keyList &#x3D; stockInfo.find_all(&#39;dt&#39;)            valueList &#x3D; stockInfo.find_all(&#39;dd&#39;)            for i in range(len(keyList)):                key &#x3D; keyList[i].text                val &#x3D; valueList[i].text                infoDict[key] &#x3D; val            with open(fpath, &#39;a&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:                f.write(str(infoDict) + &#39;\n&#39;)                count &#x3D; count + 1                print(&#39;\r当前完成进度：&#123;:.2f&#125;%&#39;.format(count * 100 &#x2F; len(lst)), end&#x3D;&quot; &quot;)        except:            count &#x3D; count + 1            print(&#39;\r当前完成进度：&#123;:.2f&#125;%&#39;.format(count * 100 &#x2F; len(lst)), end&#x3D;&quot; &quot;)            continuedef main():    stock_list_url &#x3D; &#39;https:&#x2F;&#x2F;hq.gucheng.com&#x2F;gpdmylb.html&#39;    stock_info_url &#x3D; &#39;https:&#x2F;&#x2F;hq.gucheng.com&#x2F;&#39;    output_file &#x3D; &#39;D:&#x2F;&#x2F;StockInfo.txt&#39;    slist &#x3D; []    getStockList(slist, stock_list_url)    getStockInfo(slist, stock_info_url, output_file)main()</code></pre><p>简单说，就是找到各个数据所在的标签，然后读取保存到本地文件。</p><p>同时进行了一部分优化，比如网页编码在已知的前提下可以直接引用，getHTMLText(url, code=’utf-8’)。</p><p>因为爬取信息比较多，可以添加计数功能，这里是采用x%，也可以用count / len(lst)显示更为直观。</p><p>附CSDN上<a href="https://blog.csdn.net/Guanhai1617/article/details/104123303">中财网的爬虫实例</a></p><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=45">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/19/python-c-10">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.淘宝商品信息定向爬虫实例</title>
      <link href="2020/11/13/python-c-8/"/>
      <url>2020/11/13/python-c-8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-vWmGKist" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="255644" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #6495ED"    ></div><p>&nbsp;</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a><strong>准备工作</strong></h1><p>目标：获取淘宝搜索页面的信息，提取其中的商品名称和价格。</p><p>难点：淘宝的搜索接口、翻页的处理。</p><p>工具：requests-re</p><p>&nbsp;</p><p>在淘宝搜索“书包”，起始页URL链接</p><p><code>https://s.taobao.com/search?q=书包&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20201113&amp;ie=utf8</code></p><p>第二页</p><p><code>https://s.taobao.com/search?q=书包&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20201113&amp;ie=utf8&amp;bcoffset=3&amp;ntoffset=3&amp;p4ppushleft=1%2C48&amp;s=44</code></p><p>第三页</p><p><code>https://s.taobao.com/search?q=书包&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20201113&amp;ie=utf8&amp;bcoffset=0&amp;ntoffset=6&amp;p4ppushleft=1%2C48&amp;s=88</code></p><p>分析得出q后为搜索词，s后为页面标签。</p><p>然后看一下淘宝根目录s.taobao.com的robots协议</p><pre class="language-html" data-language="html"><code class="language-html">User-agent: *Disallow: /</code></pre><p>不允许任何爬虫爬取任何资源，<del>好的本章到此结束，下一章节见</del></p><p>因轻量学习性爬取不会对服务器造成负担，可以限制性爬取。</p><p>&nbsp;</p><p>可分为三个步骤</p><ol><li>提交商品搜索请求，循环获取页面getHTMLText()。</li><li>对于每个页面，提取商品名称和价格信息parsepage()。</li><li>将信息输出printGoodsList()。</li></ol><p>&nbsp;</p><h1 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a><strong>爬虫编写</strong></h1><pre class="language-none"><code class="language-none">import requestsimport recookie &#x3D; &#123;    &#39;cookie&#39;: &#39;&#39;,&#125;def getHTMLText(url):    try:        r &#x3D; requests.get(url, cookies&#x3D;cookie, timeout&#x3D;30)        r.raise_for_status()        r.encoding &#x3D; r.apparent_encoding        return r.text    except:        return &quot;&quot;def parsePage(ilt,html):    try:        plt &#x3D; re.findall(r&#39;\&quot;view_price\&quot;:\&quot;[\d+\.]*\&quot;&#39;,html)        tlt &#x3D; re.findall(r&#39;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&#39;,html)        for i in range(len(plt)):            price &#x3D; eval(plt[i].split(&#39;:&#39;)[1])            title &#x3D; eval(tlt[i].split(&#39;:&#39;)[1])            ilt.append([price,title])    except:        print(&quot;&quot;)def printGoodsList(ilt):    tplt &#x3D; &quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;&quot;    print(tplt.format(&quot;序号&quot;, &quot;价格&quot;, &quot;商品名称&quot;))    count &#x3D; 0    for g in ilt:        count &#x3D; count + 1        print(tplt.format(count, g[0], g[1]))def main():    goods &#x3D; &#39;书包&#39;    depth &#x3D; 2    start_url &#x3D; &#39;https:&#x2F;&#x2F;s.taobao.com&#x2F;search?q&#x3D;&#39; + goods    infoList &#x3D; []    for i in range(depth):        try:            url &#x3D; start_url + &#39;&amp;s&#x3D;&#39; + str(44*i)            html &#x3D; getHTMLText(url)            parsePage(infoList, html)        except:            continue    printGoodsList(infoList)main()</code></pre><p>因淘宝升级了反爬虫技术。</p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/bqb-sdbl.jpg" alt="Audits - Lighthouse" style="zoom: 200%;" / loading="lazy"><p>这里对爬虫进行了伪装，替换cookies，否则无法访问。</p><p>在csdn上看到，还有一种通用的<a href="https://blog.csdn.net/Omann/article/details/104759719/">解决方法</a>，更加全面。</p><p><a href="https://curl.trillworks.com/">curl.trillworks.com</a>提供将访问信息转换成requests库可读取信息的功能。</p><p>直接替换header进行伪装即可。</p><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=42">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/14/python-c-9">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Re库入门</title>
      <link href="2020/11/06/python-c-7/"/>
      <url>2020/11/06/python-c-7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-joyjFozg" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1488737309" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #6495ED"    ></div><p>&nbsp;</p><h1 id="Re库：正则表达式库"><a href="#Re库：正则表达式库" class="headerlink" title="Re库：正则表达式库"></a><strong>Re库：正则表达式库</strong></h1><p>regular expression：通用的字符串表达框架，用来<strong>简洁</strong>表达一组<strong>字符串</strong>的表达式。</p><p>在文本处理中，可用于表达文本类型的特征，同时查找或替换一组字符串，匹配字符串的全部或部分。</p><p>&nbsp;</p><h2 id="Re库的常用操作符"><a href="#Re库的常用操作符" class="headerlink" title="Re库的常用操作符"></a><strong>Re库的常用操作符</strong></h2><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/zzbds1.jpg" alt="Audits - Lighthouse" loading="lazy"><br><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/zzbds2.jpg" alt="Audits - Lighthouse" loading="lazy"><br><strong>举栗</strong><br><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/zzbds3.jpg" alt="Audits - Lighthouse" loading="lazy"><br><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/zzbds4.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><h2 id="Re库的表示类型"><a href="#Re库的表示类型" class="headerlink" title="Re库的表示类型"></a><strong>Re库的表示类型</strong></h2><p>re库采用<strong>raw string类型</strong>（原生字符串类型,<strong>不包含转义符</strong>），形式为r’text’</p><p>例如：邮政编码r’[1-9]\d{5}’</p><p>这里的\就不包含转义含义，如果用string类型需要额外添加一个\</p><p>&nbsp;</p><h2 id="Re库主要功能函数"><a href="#Re库主要功能函数" class="headerlink" title="Re库主要功能函数"></a><strong>Re库主要功能函数</strong></h2><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">re.search()</td><td align="left">在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象</td></tr><tr><td align="left">re.match()</td><td align="left">从一个字符串的开始位置起匹配正则表达式，返回match对象</td></tr><tr><td align="left">re.findall()</td><td align="left">搜索字符串，以<strong>列表类型</strong>返回全部能匹配的子串</td></tr><tr><td align="left">re.split()</td><td align="left">将一个字符串按照正则表达式匹配结果进行分割，返回<strong>列表类型</strong></td></tr><tr><td align="left">re.finditer()</td><td align="left">搜索字符串，返回一个匹配结果的<strong>迭代类型</strong>，每个迭代元素是math对象</td></tr><tr><td align="left">re.sub()</td><td align="left">在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td></tr></tbody></table><p>&nbsp;</p><h3 id="search函数"><a href="#search函数" class="headerlink" title="search函数"></a><strong>search函数</strong></h3><p>re.search(pattern,string,flags=0)</p><p>pattern:正则表达式的字符串或原生字符串表示</p><p>string:待匹配字符串</p><p>flags:正则表达式使用时的<strong>控制标记</strong></p><table><thead><tr><th align="left">常用标记</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">re.I re.IGNORECASE</td><td align="left">忽略正则表达式的大小写，[A-Z]能苟匹配小写字符</td></tr><tr><td align="left">re.M re.MULTILINE</td><td align="left">正则表达式中^操作符能够将给定字符串的每行当做匹配开始</td></tr><tr><td align="left">re.S re.DOTALL</td><td align="left">正则表达式中的.操作符能够匹配所有字符，默认匹配除换行外的所有字符</td></tr></tbody></table><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> rematch <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'BIT 100081'</span><span class="token punctuation">)</span><span class="token keyword">if</span> match<span class="token punctuation">:</span>    printf<span class="token punctuation">(</span>match<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h3 id="match函数"><a href="#match函数" class="headerlink" title="match函数"></a><strong>match函数</strong></h3><p>re.match(pattern,string,flags=0)</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> rematch <span class="token operator">=</span> re<span class="token punctuation">.</span>match<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'100081 BIT'</span><span class="token punctuation">)</span><span class="token keyword">if</span> match<span class="token punctuation">:</span>    printf<span class="token punctuation">(</span>match<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h3 id="findall函数"><a href="#findall函数" class="headerlink" title="findall函数"></a><strong>findall函数</strong></h3><p>re.findall(pattern,string,flags=0)</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> rels <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'BIT100081 TSU100084'</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h3 id="split函数"><a href="#split函数" class="headerlink" title="split函数"></a><strong>split函数</strong></h3><p>re.split(pattern,string,maxsplit=0,flags=0)</p><p>maxsplit:最大分割数，剩余部分作为最后一个元素输出</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> rels <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'BIT100081 TSU100084'</span><span class="token punctuation">)</span><span class="token comment">#['BIT', ' TSU', '']</span>ls <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'BIT100081 TSU100084'</span><span class="token punctuation">)</span><span class="token comment">#['BIT', ' TSU100084']</span></code></pre><p>&nbsp;</p><h3 id="finditer函数"><a href="#finditer函数" class="headerlink" title="finditer函数"></a><strong>finditer函数</strong></h3><p>re.finditer(pattern,string,flags=0)</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">for</span> m <span class="token keyword">in</span> re<span class="token punctuation">.</span>finditer<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'BIT100081 TSU100084'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> m<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h3 id="sub函数"><a href="#sub函数" class="headerlink" title="sub函数"></a><strong>sub函数</strong></h3><p>re.sub(pattern,repl,string,count=0,flags=0)</p><p>repl:替换匹配字符串的字符串</p><p>count:匹配的最大替换次数</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> rere<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">':zipcode'</span><span class="token punctuation">,</span> <span class="token string">'BIT100081 TSU100084'</span><span class="token punctuation">)</span><span class="token comment">#'BIT:zipcode TSU:zipcode'</span></code></pre><p>&nbsp;</p><h2 id="match对象"><a href="#match对象" class="headerlink" title="match对象"></a><strong>match对象</strong></h2><h3 id="match对象属性"><a href="#match对象属性" class="headerlink" title="match对象属性"></a><strong>match对象属性</strong></h3><p>re库的search，match，finditer函数都会返回match对象</p><p>可以通过type(match)查看属性，介绍以下四种</p><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.string</td><td align="left">待匹配的文本</td></tr><tr><td align="left">.re</td><td align="left">匹配时使用的pattern对象（正则表达式）</td></tr><tr><td align="left">.pos</td><td align="left">正则表达式搜索文本的开始位置</td></tr><tr><td align="left">.endpos</td><td align="left">正则表达式搜索文本的结束位置</td></tr></tbody></table><p>&nbsp;</p><h3 id="match对象的方法"><a href="#match对象的方法" class="headerlink" title="match对象的方法"></a><strong>match对象的方法</strong></h3><table><thead><tr><th align="left">方法</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.group(0)</td><td align="left">获得匹配后的字符串</td></tr><tr><td align="left">.start()</td><td align="left">匹配字符串在原始字符串的开始位置</td></tr><tr><td align="left">.end</td><td align="left">匹配字符串在原始字符串的结束位置</td></tr><tr><td align="left">.span</td><td align="left">返回(.start(),.end())</td></tr></tbody></table><p>&nbsp;</p><h3 id="match对象应用实例"><a href="#match对象应用实例" class="headerlink" title="match对象应用实例"></a><strong>match对象应用实例</strong></h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> rem <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">r'[1-9]\d&#123;5&#125;'</span><span class="token punctuation">,</span> <span class="token string">'BIT100081 TSU100084'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>string<span class="token punctuation">)</span><span class="token comment">#BIT100081 TSU100084</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>re<span class="token punctuation">)</span><span class="token comment">#re.compile('[1-9]\\d&#123;5&#125;')#compile函数下面有介绍</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>pos<span class="token punctuation">)</span><span class="token comment">#0</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>endpos<span class="token punctuation">)</span><span class="token comment">#19</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#100081返回第一次匹配</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#3</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#9</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>span<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#(3, 9)</span></code></pre><p>&nbsp;</p><h2 id="Re库的另一种等价用法"><a href="#Re库的另一种等价用法" class="headerlink" title="Re库的另一种等价用法"></a><strong>Re库的另一种等价用法</strong></h2><p><strong>函数式用法：一次性操作</strong></p><p><code>rst = re.search(r&#39;[1-9]\d&#123;5&#125;&#39;, &#39;BIT100081&#39;)</code></p><p>&nbsp;</p><p><strong>面向对象用法：编译后的多次操作</strong></p><p><code>pat = re.compile(r&#39;[1-9]\d&#123;5&#125;&#39;)</code></p><p><code>rst = pat.search(&#39;BIT100081&#39;)</code></p><p>&nbsp;</p><p><strong>补充compile函数</strong></p><p>将正则表达式的字符串形式编译成正则表达式对象    </p><p>re.compile(pattern,flags=0)</p><p>&nbsp;</p><h2 id="Re库的贪婪匹配和最小匹配"><a href="#Re库的贪婪匹配和最小匹配" class="headerlink" title="Re库的贪婪匹配和最小匹配"></a><strong>Re库的贪婪匹配和最小匹配</strong></h2><pre class="language-python" data-language="python"><code class="language-python">match <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">r'PY.*N'</span><span class="token punctuation">,</span> <span class="token string">'PYANBNCNDN'</span><span class="token punctuation">)</span>match<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre><p>同时匹配长短不同的多项，Re库采用贪婪匹配，即输出匹配最长的子串’PYANBNCNDN’。</p><p>那如何输出最短的子串？</p><p>只需将正则表达式修改为<code>r&#39;PY.*?N&#39;</code></p><p>具体介绍最小匹配操作符</p><table><thead><tr><th align="left">操作符</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">*?</td><td align="left">前一个字符0次或无限次扩展，最小匹配</td></tr><tr><td align="left">+?</td><td align="left">前一个字符1次或无限次扩展，最小匹配</td></tr><tr><td align="left">??</td><td align="left">前一个字符0次或1次扩展，最小匹配</td></tr><tr><td align="left">{m,n}?</td><td align="left">扩展前一个字符m至n次（含n），最小匹配</td></tr></tbody></table><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=38">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/13/python-c-8">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.中国大学排名定向爬虫实例</title>
      <link href="2020/11/05/python-c-6/"/>
      <url>2020/11/05/python-c-6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-AbrSJTxV" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="864100348" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #C0C0C0"    ></div><p>&nbsp;</p><p>在记录笔记过程中发现视频的代码无法正常实现，毕竟过了4年，html格式也发生了变化，下面是修改后的2020年爬取代码示例。</p><p><strong>先了解一下定向爬取：仅对输入URL进行爬去，不扩展爬取。</strong></p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a><strong>准备工作</strong></h1><p><strong>功能：</strong></p><p>输入：大学排名URL链接。</p><p>输出：大学排名信息的屏幕输出（排名、大学名称、总分。）</p><details><summary>确定可行性</summary>观察返回的信息是否写在HTML页面，有部分数据可能是通过JavaScript等脚本语言生成的（动态数据），仅通过requests及bs4无法获取。</details><p>&nbsp;</p><p>可分为三个步骤</p><ol><li>从网络上获取大学排名网页内容&nbsp;getHTMLText()</li><li>提取网页内容中信息到合适的数据结构&nbsp;fillUnivList()</li><li>利用数据结构展示并输出结果&nbsp;printUnivList()</li></ol><p>&nbsp;</p><h1 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a><strong>爬虫编写</strong></h1><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup<span class="token keyword">import</span> bs4<span class="token keyword">def</span> <span class="token function">getHTMLText</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>        r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>        r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding        <span class="token keyword">return</span> r<span class="token punctuation">.</span>text    <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token keyword">def</span> <span class="token function">fillUnivList</span><span class="token punctuation">(</span>ulist<span class="token punctuation">,</span> html<span class="token punctuation">)</span><span class="token punctuation">:</span>    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> tr <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'tbody'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>children<span class="token punctuation">:</span><span class="token comment"># 在tbody标签中找到tr标签</span>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tr<span class="token punctuation">,</span> bs4<span class="token punctuation">.</span>element<span class="token punctuation">.</span>Tag<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 检测tr标签的类型，如果不是bs4定义的Tag会过滤掉</span>            tds <span class="token operator">=</span> tr<span class="token punctuation">(</span><span class="token string">'td'</span><span class="token punctuation">)</span><span class="token comment"># 将筛选后的td标签加入列表中</span>            <span class="token keyword">for</span> a <span class="token keyword">in</span> tr<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#找到大学名称标签</span>                ulist<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>tds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>string<span class="token punctuation">,</span> a<span class="token punctuation">,</span> tds<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>string<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">printUnivList</span><span class="token punctuation">(</span>ulist<span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"       &#123;:^10&#125;\t    &#123;:^10&#125;\t        &#123;:^10&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"排名"</span><span class="token punctuation">,</span><span class="token string">"学校名称"</span><span class="token punctuation">,</span><span class="token string">"总分"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>        u <span class="token operator">=</span> ulist<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"&#123;:^10&#125;\t&#123;:^10&#125;\t&#123;:^10&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>u<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token builtin">chr</span><span class="token punctuation">(</span><span class="token number">12288</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> u<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token builtin">chr</span><span class="token punctuation">(</span><span class="token number">12288</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> u<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token builtin">chr</span><span class="token punctuation">(</span><span class="token number">12288</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    uinfo <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    url <span class="token operator">=</span> <span class="token string">"https://www.shanghairanking.cn/rankings/bcur/2020"</span>    html <span class="token operator">=</span> getHTMLText<span class="token punctuation">(</span>url<span class="token punctuation">)</span>    fillUnivList<span class="token punctuation">(</span>uinfo<span class="token punctuation">,</span> html<span class="token punctuation">)</span>    printUnivList<span class="token punctuation">(</span>uinfo<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token comment">#前20名</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>在第一个函数中，观察网页源代码发现大学名称在a标签中，而排名与总分记录在td标签，要单独取出来。</p><p>引入了一个<a href="https://www.runoob.com/python/att-string-format.html">format函数</a>，简单说明</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/formatlz.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><h1 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a><strong>补充说明</strong></h1><p>ulist中含有的换行符会导致排版不整齐，需要使用 replace() 方法替换</p><p>但替换后仍不整齐，原因是如果列表数据宽度不够，系统默认使用英文空格填充，可以通过中文空格的字符chr(12288)填充。</p><p>另外，在不同环境下输出格式可能会有所不同，需要根据情况选择更改。</p><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=31">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/06/python-c-7">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.信息组织与提取方法</title>
      <link href="2020/11/02/python-c-5/"/>
      <url>2020/11/02/python-c-5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-CObWjqxz" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="437387593" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="   #DC143C"    ></div><p>&nbsp;</p><p>本节内容是对beautiful库的补充，介绍获取资源后如何进行下一步的操作与查找。</p><h1 id="信息标记"><a href="#信息标记" class="headerlink" title="信息标记"></a><strong>信息标记</strong></h1><p>为什么需要信息标记？假如给出一组信息，’北京理工大学’；’1940’；’北京市海淀区中关村’。</p><p>我们需要对信息做一定的标记，来理解信息的真实含义。</p><p>例如’name’:’北京理工大学’    addr:’北京市海淀区中关村’    ‘year’:’1940’。</p><ul><li><p>标记后的信息可形成信息组织结构，增加了信息维度</p></li><li><p>标记后的信息可用于通信、存储或展示</p></li><li><p>标记的结构与信息一样具有重要价值</p></li><li><p>标记后的信息更利于程序理解和运用</p></li></ul><p>&nbsp;</p><h2 id="HTML的信息标记"><a href="#HTML的信息标记" class="headerlink" title="HTML的信息标记"></a><strong>HTML的信息标记</strong></h2><p>HTML是WWW（World Wide Web）的信息组织方式，能够将<strong>声音 图像 视频等超文本信息</strong>嵌入到文本中。</p><p>HTML通过预定义的&lt;&gt;…&lt;/&gt;标签形式组织不同类型的信息</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmljbgs.jpg" alt="Audits - Lighthouse" loading="lazy"></p><hr><p>&nbsp;</p><h2 id="信息标记的三种形式"><a href="#信息标记的三种形式" class="headerlink" title="信息标记的三种形式"></a><strong>信息标记的三种形式</strong></h2><h3 id="XML：扩展标记语言"><a href="#XML：扩展标记语言" class="headerlink" title="XML：扩展标记语言"></a><strong>XML：扩展标记语言</strong></h3><p>采用以标签为主来构建信息、表达信息的方式。</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>china,jpg<span class="token punctuation">"</span></span> <span class="token attr-name">size</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>10<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>img</span><span class="token punctuation">></span></span></code></pre><p>名称Name：img</p><p>属性Attribute：src=”china,jpg” size=”10”</p><p>若标签中没有内容，则可以用空元素的缩写形式</p><pre class="language-sml" data-language="sml"><code class="language-sml"><span class="token operator">&lt;</span>img src<span class="token operator">=</span><span class="token string">"china,jpg"</span> size<span class="token operator">=</span><span class="token string">"10"</span> <span class="token operator">/</span><span class="token operator">></span></code></pre><p>注释形式</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- This is a comment, very useful --></span></code></pre><p>&nbsp;</p><h3 id="JSON：JavaScript中对面向对象信息的一种表达形式"><a href="#JSON：JavaScript中对面向对象信息的一种表达形式" class="headerlink" title="JSON：JavaScript中对面向对象信息的一种表达形式"></a><strong>JSON：JavaScript中对面向对象信息的一种表达形式</strong></h3><p>有类型的键值对key:value构建的信息表达方式</p><p><code>&quot;name&quot;:&quot;北京理工大学&quot;</code>（name为键key，北京理工大学为值value）</p><p><code>&quot;year&quot;:1940</code></p><p>当一个键对应多个值的时候，用[，]组织</p><p><code>&quot;name&quot;:[&quot;北京理工大学&quot;,&quot;延安自然科学院&quot;]</code></p><p>键值对的嵌套使用：</p><p><code>&quot;name&quot;:&#123;&quot;newName&quot;:&quot;北京理工大学&quot;,&quot;oldName&quot;:&quot;延安自然科学院&quot;&#125;</code></p><p>&nbsp;</p><h3 id="YAML：表达数据序列化的格式"><a href="#YAML：表达数据序列化的格式" class="headerlink" title="YAML：表达数据序列化的格式"></a><strong>YAML：表达数据序列化的格式</strong></h3><p>使用无类型键值对key:value</p><p><code>name:北京理工大学</code></p><p>通过缩进的形式表达所属关系</p><pre class="language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">name</span><span class="token punctuation">:</span>newName<span class="token punctuation">:</span>北京理工大学oldName<span class="token punctuation">:</span>延安自然科学院</code></pre><p>使用-表达并列关系</p><pre class="language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">name</span><span class="token punctuation">:</span><span class="token punctuation">-</span>北京理工大学<span class="token punctuation">-</span>延安自然科学院</code></pre><p>|表达整块数据，信息过多时使用</p><p>#表示注释</p><p>&nbsp;</p><h3 id="三种信息标记形式的比较"><a href="#三种信息标记形式的比较" class="headerlink" title="三种信息标记形式的比较"></a><strong>三种信息标记形式的比较</strong></h3><p>XML ：最早的通用信息标记语言，可扩展性好，但繁琐。用于Internet上的信息交互与传递。</p><p>JSON：信息有类型，适合程序处理（js），较XML简洁。移动应用云端和节点的信息通信，无注释。</p><p>YAML：信息无类型，文本信息比例最高，可读性好。各类系统的配置文件，有注释易读。</p><p>&nbsp;</p><h4 id="XML实例："><a href="#XML实例：" class="headerlink" title="XML实例："></a><strong>XML实例：</strong></h4><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>person</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>firstName</span><span class="token punctuation">></span></span>Tian<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>firstName</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>lastName</span><span class="token punctuation">></span></span>Song<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>lastName</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>address</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>streetAddr</span><span class="token punctuation">></span></span>中关村<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>streetAddr</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>city</span><span class="token punctuation">></span></span>北京市<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>city</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>zipcode</span><span class="token punctuation">></span></span>100081<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>zipcode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>address</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>prof</span><span class="token punctuation">></span></span>Computer System<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>prof</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>prof</span><span class="token punctuation">></span></span>Security<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>prof</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>person</span><span class="token punctuation">></span></span></code></pre><p>&nbsp;</p><h4 id="JSON实例："><a href="#JSON实例：" class="headerlink" title="JSON实例："></a><strong>JSON实例：</strong></h4><pre class="language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>    <span class="token property">"firstName"</span><span class="token operator">:</span><span class="token string">"Tian"</span><span class="token punctuation">,</span>    <span class="token property">"lastName"</span><span class="token operator">:</span><span class="token string">"Song"</span><span class="token punctuation">,</span>    <span class="token property">"address"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>        <span class="token property">"streetAddr"</span><span class="token operator">:</span><span class="token string">"中关村南大街5号"</span><span class="token punctuation">,</span>        <span class="token property">"city"</span><span class="token operator">:</span><span class="token string">"北京市"</span><span class="token punctuation">,</span>        <span class="token property">"zipcode"</span><span class="token operator">:</span><span class="token string">"100081"</span>     <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token property">"prof"</span>    <span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"Computer System"</span><span class="token punctuation">,</span><span class="token string">"Security"</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></code></pre><p>&nbsp;</p><h4 id="YAML实例："><a href="#YAML实例：" class="headerlink" title="YAML实例："></a><strong>YAML实例：</strong></h4><pre class="language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">firstName</span><span class="token punctuation">:</span> Tian<span class="token key atrule">lastName</span><span class="token punctuation">:</span> Song<span class="token key atrule">address</span><span class="token punctuation">:</span><span class="token key atrule">streetAddr</span><span class="token punctuation">:</span> 中关村南大街5号<span class="token key atrule">city</span><span class="token punctuation">:</span> 北京市<span class="token key atrule">zipcode"</span><span class="token punctuation">:</span> <span class="token number">100081</span><span class="token key atrule">prof</span>    <span class="token punctuation">:</span><span class="token punctuation">-</span>Computer System<span class="token punctuation">-</span>Security</code></pre><p>&nbsp;</p><h2 id="信息提取的一般方法"><a href="#信息提取的一般方法" class="headerlink" title="信息提取的一般方法"></a><strong>信息提取的一般方法</strong></h2><h3 id="方法一：完整解析信息的标记形式，再提取关键信息"><a href="#方法一：完整解析信息的标记形式，再提取关键信息" class="headerlink" title="方法一：完整解析信息的标记形式，再提取关键信息"></a><strong>方法一：完整解析信息的标记形式，再提取关键信息</strong></h3><p>就是用标记解析器去解析XML JSON YAML格式，再将其中所需要的信息提取出来。</p><p>例如bs4库提供了对标签树的遍历，需要解析什么信息对标签树遍历即可。</p><p>优点：信息解析准确。</p><p>缺点：提取过程繁琐，速度慢。</p><p>&nbsp;</p><h3 id="方法二：无视标记形似，直接搜索关键信息"><a href="#方法二：无视标记形似，直接搜索关键信息" class="headerlink" title="方法二：无视标记形似，直接搜索关键信息"></a><strong>方法二：无视标记形似，直接搜索关键信息</strong></h3><p>搜索</p><p>对信息的文本查找函数即可。</p><p>优点：提取过程简洁，速度较快。</p><p>缺点：提取结果准确性与信息内容相关。</p><p>&nbsp;</p><p><strong>实际使用中通常将两种方法结合起来使用，需要这就需要了标记解析器及文本查找函数。</strong></p><p>例如提取HTML中所有URL链接</p><p>思路：1.搜索到所有<code>&lt;a&gt;</code>标签</p><p>​            2.解析<code>&lt;a&gt;</code>标签格式，提取href后的链接内容</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token keyword">for</span> link <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>link<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>例为在a标签中获取所有url链接</p><p>&nbsp;</p><h1 id="基于bs4库的HTML内容查找方法"><a href="#基于bs4库的HTML内容查找方法" class="headerlink" title="基于bs4库的HTML内容查找方法"></a><strong>基于bs4库的HTML内容查找方法</strong></h1><h2 id="find-all方法"><a href="#find-all方法" class="headerlink" title="find_all方法"></a><strong>find_all方法</strong></h2><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">&lt;></span><span class="token punctuation">.</span>find_all<span class="token punctuation">(</span>name<span class="token punctuation">,</span>attrs<span class="token punctuation">,</span>recursive<span class="token punctuation">,</span>string<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></code></pre><p>返回一个列表类型，存储查找的结果。</p><ul><li>name：对标签名称的检索字符串。</li><li>attrs：对标签属性值的检索字符串，可标注属性检索。</li><li>recursive：是否对子孙全部检索，默认为True。</li><li>string：&lt;&gt;…&lt;/&gt;中字符串区域的检索字符串。</li></ul><p>&nbsp;</p><h3 id="name解释"><a href="#name解释" class="headerlink" title="name解释"></a><strong>name解释</strong></h3><p><code>soup.find_all(&#39;a&#39;)</code>返回一个列表类型，包含了这个文件中所有的a标签。</p><p><code>soup.find_all([&#39;a&#39;,&#39;b&#39;])</code>返回一个列表类型，包含了这个文件中所有的a、b标签。</p><p><code>soup.find_all(True)</code>返回一个列表类型，包含了这个文件中所有的标签。</p><p>以上都是查找具体名称，如果我们需要查找文件的部分名称，例如以b开头的标签，就需要使用正则表达式库。</p><p>简略介绍一下，后续会深入学习</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">for</span> tag <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span>re<span class="token punctuation">.</span>complile<span class="token punctuation">(</span><span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>tag<span class="token punctuation">.</span>name<span class="token punctuation">)</span></code></pre><p>返回的结果则为以b开头的标签名称。</p><p>&nbsp;</p><h3 id="attrs解释"><a href="#attrs解释" class="headerlink" title="attrs解释"></a><strong>attrs解释</strong></h3><p>附加该参数会返回带有该属性的标签。例如：</p><p><code>soup.find_all(&#39;a&#39;,&#39;course&#39;)</code></p><p>返回带有course属性的a标签。</p><p>也可直接对属性做相关约定，以查找id属性=link1的值作为查找元素。</p><p><code>soup.find_all(id=&#39;link1&#39;)</code></p><p>有则返回该标签，无则返回空。</p><p>但这种查找方式必须对属性精确赋值，如果我们想用其中的一部分进行查找（例如输入link可以得到link1、2、3的内容）就需要引用正则表达式库。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">for</span> tag <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token builtin">id</span><span class="token operator">=</span>re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'link'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>tag<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h3 id="recursive解释"><a href="#recursive解释" class="headerlink" title="recursive解释"></a><strong>recursive解释</strong></h3><p>默认搜索某一个标签开始的后续所有子孙节点的信息，如果只想搜索当前子节点的信息，可设为false。</p><p>例如soup根节点的子孙节点中含有a标签，但其子节点无a标签则：</p><p><code>soup.find_all(&#39;a&#39;)</code>会返回a标签</p><p><code>soup.find_all(&#39;a&#39;,recursive=False)</code>返回空</p><p>&nbsp;</p><h3 id="string解释"><a href="#string解释" class="headerlink" title="string解释"></a><strong>string解释</strong></h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> tag <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span>string <span class="token operator">=</span> <span class="token string">"Basic Python"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">print</span><span class="token punctuation">(</span>tag<span class="token punctuation">)</span></code></pre><p>若有该字符串，返回该字符串</p><p>同样，利用正则表达式库可以部分检索。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">for</span> tag <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span>string <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">"Python"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>tag<span class="token punctuation">)</span></code></pre><p>则会检索全部含Python的字符串。</p><p>&nbsp;</p><h2 id="find简略写法"><a href="#find简略写法" class="headerlink" title="find简略写法"></a><strong>find简略写法</strong></h2><p><code>&lt;tag&gt;(..)</code> = <code>&lt;tag&gt;.find_all(..)</code></p><p><code>soup(..)</code> = <code>soup.find_all(..)</code></p><p>&nbsp;</p><h2 id="find的一些扩展方法"><a href="#find的一些扩展方法" class="headerlink" title="find的一些扩展方法"></a><strong>find的一些扩展方法</strong></h2><table><thead><tr><th align="left">方法</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">&lt;&gt;.find</td><td align="left">搜索且只返回一个结果，字符串类型，同.find_all()参数</td></tr><tr><td align="left">&lt;&gt;.find_parents()</td><td align="left">在先辈节点中搜索，返回列表类型，同.find_all()参数</td></tr><tr><td align="left">&lt;&gt;.find_parent()</td><td align="left">在先辈节点中返回一个结果，字符串类型，同.find()参数</td></tr><tr><td align="left">&lt;&gt;.find_next_siblings()</td><td align="left">在后续平行节点中搜索，返回列表类型，同.find_all()参数</td></tr><tr><td align="left">&lt;&gt;.find_next_sibling()</td><td align="left">在后续平行节点中返回一个结果，字符串类型，同.find()参数</td></tr><tr><td align="left">&lt;&gt;.find_previous_siblings()</td><td align="left">在前序平行节点中搜索，返回列表类型，同.find_all()参数</td></tr><tr><td align="left">&lt;&gt;.find_previous_sibling()</td><td align="left">在前序平行节点中返回一个结果，字符串类型，同.find()参数</td></tr></tbody></table><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=24">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/05/python-c-6">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.BeautifulSoup库入门</title>
      <link href="2020/10/30/python-c-4/"/>
      <url>2020/10/30/python-c-4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-AqOdIbMx" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1387601942" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="  #E6E6FA"    ></div><p>&nbsp;</p><p><strong>在学习之前了解一下，为什么要引入BeautifulSoup库？</strong>根据前三节的学习，我们已经可以做到从网站上爬取需要的内容，并且打印出来，但仅仅局限于打印这些html，无法有效利用。后续操作就需要用到Beautifulsoup，解析html代码或是sml文档。</p><h1 id="BeautifulSoup库"><a href="#BeautifulSoup库" class="headerlink" title="BeautifulSoup库"></a><strong>BeautifulSoup库</strong></h1><p><code>官网：https://www.crummy.com/software/BeautifulSoup/</code></p><details><summary>官方解释</summary>Beautiful Soup 提供一些简单的、python 式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。 Beautiful Soup 自动将输入文档转换为 Unicode 编码，输出文档转换为 utf-8 编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup 就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。 Beautiful Soup 已成为和 lxml、html6lib 一样出色的 python 解释器，为用户灵活地提供不同的解析策略或强劲的速度。</details><p>使用方法：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup<span class="token comment">#从bs4中引入一个类，即BeautifulSoup</span>soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span><span class="token string">'&lt;p>data&lt;/p>'</span><span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>soup2 <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"D://demo.html"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span></code></pre><p><strong>data为需要bs4解析的html信息(可以是r.text或是引入文件)</strong></p><p><strong>html.parser为解析器</strong></p><p>&nbsp;</p><h2 id="BeautifulSoup库的理解"><a href="#BeautifulSoup库的理解" class="headerlink" title="BeautifulSoup库的理解"></a><strong>BeautifulSoup库的理解</strong></h2><p>首先源文件，即从浏览器中<strong>查看网页源代码</strong>或是通过<strong>requests库get到的text文件</strong>类型都如下图一般，由一对尖括号构成的标签组织起来的，每一对尖括号形成一对标签，标签之间存在上下元关系，从而形成一个<strong>标签树</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmlbqs.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>标签树分析，例如</p><pre class="language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>title<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    ...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span></code></pre><ul><li><p>p：标签的Name，成对出现</p></li><li><p>class=”title”：属性Attributes（属性域），包含0个或多个属性，用以定义标签的特点，由键值对构成。</p></li></ul><p><strong>Beautiful Soup库即是解析、遍历、维护“标签树”的功能库，也称beautifulsoup4或者bs4</strong></p><p>标签树可经BeautifulSoup处理转换成BeautifulSoup类，通常认为html文档，标签树，BeautifulSoup类三者等价。</p><p>&nbsp;</p><h2 id="BeautifulSoup类的基本元素"><a href="#BeautifulSoup类的基本元素" class="headerlink" title="BeautifulSoup类的基本元素"></a><strong>BeautifulSoup类的基本元素</strong></h2><table><thead><tr><th align="left">基本元素</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">Tag</td><td align="left">标签，最基本的信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾</td></tr><tr><td align="left">Name</td><td align="left">标签的名字，<code>&lt;p&gt;...&lt;/p&gt;</code>的名字是’p’，格式：<code>&lt;tag&gt;.name</code></td></tr><tr><td align="left">Attributes</td><td align="left">标签的属性，字典形式组织，格式：<code>&lt;tag&gt;.attrs</code></td></tr><tr><td align="left">NavigableString</td><td align="left">标签内非属性字符串，&lt;&gt;…&lt;/&gt;中的字符串，格式：<code>&lt;tag&gt;.string</code></td></tr><tr><td align="left">Comment</td><td align="left">标签内字符串的注释部分，一种特殊的Comment类型</td></tr></tbody></table><p>标签获取方法，例如</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding<span class="token comment">#调整编码</span>soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token comment">#解析获取的html</span><span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>title<span class="token punctuation">)</span><span class="token comment">#输出title标签</span><span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>a<span class="token punctuation">)</span><span class="token comment">#输出a标签，即链接标签</span></code></pre><p>为了方便，我们可以令<strong>tag = soup.a</strong>。对tag进行上表变换，例如</p><pre class="language-html" data-language="html"><code class="language-html">tag = soup.atag.name#a标签的名称"a"tag.attrs['class']#a标签[class]属性tag.string#标签的字符串信息type（tag.attrs)#标签属性类型type（tag)#标签类型type（tag.comment)#注释类型</code></pre><p><strong>我们也可以通过tag.parent/child来查看其父/子标签，下文会讲</strong></p><p>对标签类型判断的时候，很有可能该标签含有一个类型不同的子标签，该标签同样被bs4的标签类覆盖。</p><p>&nbsp;</p><h2 id="prettify-方法"><a href="#prettify-方法" class="headerlink" title="prettify()方法"></a><strong>prettify()方法</strong></h2><p>辅助作用，在每一个标签后加入换行符’\n’，使得输出文本容易阅读。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span>tag <span class="token operator">=</span> soup<span class="token punctuation">.</span>a<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>prettify<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#标签树</span><span class="token keyword">print</span><span class="token punctuation">(</span>tag<span class="token punctuation">.</span>prettify<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#每个标签同样适用</span></code></pre><p>&nbsp;</p><h1 id="HTML内容遍历方法"><a href="#HTML内容遍历方法" class="headerlink" title="HTML内容遍历方法"></a><strong>HTML内容遍历方法</strong></h1><h2 id="HTML基本格式"><a href="#HTML基本格式" class="headerlink" title="HTML基本格式"></a>HTML基本格式</h2><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmljbgs.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>用树来表示：</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmlbqst.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>有三种遍历方式。</p><p>&nbsp;</p><h2 id="标签树的下行遍历"><a href="#标签树的下行遍历" class="headerlink" title="标签树的下行遍历"></a><strong>标签树的下行遍历</strong></h2><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.contents</td><td align="left">子节点的列表，将<code>&lt;tag&gt;</code>所有儿子节点存入列表</td></tr><tr><td align="left">.children</td><td align="left">子节点的迭代类型，与.contents类似，用于循环遍历儿子节点</td></tr><tr><td align="left">.descendants</td><td align="left">子孙节点的迭代类型，包含所有子孙节点，用于循环遍历</td></tr></tbody></table><p>使用方法如下</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>head<span class="token punctuation">.</span>contents<span class="token punctuation">)</span></code></pre><p>我们可以用len函数获取子节点的数量</p><p><code>len(soup.head.contents)</code></p><p>因返回值是列表类型，故可以用下标来获取相关元素</p><p><code>print(soup.head.contents[1])</code></p><p><strong>下行遍历</strong></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> child <span class="token keyword">in</span> soup<span class="token punctuation">.</span>body<span class="token punctuation">.</span>children<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>child<span class="token punctuation">)</span><span class="token keyword">for</span> child <span class="token keyword">in</span> soup<span class="token punctuation">.</span>body<span class="token punctuation">.</span>descendants<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>child<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h2 id="标签树的上行遍历"><a href="#标签树的上行遍历" class="headerlink" title="标签树的上行遍历"></a><strong>标签树的上行遍历</strong></h2><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.parent</td><td align="left">节点的父亲标签</td></tr><tr><td align="left">.parents</td><td align="left">节点先辈标签的迭代类型，用于循环遍历先辈节点</td></tr></tbody></table><p>使用方法与下行类似，唯一不同soup作为一个特殊标签，父标签为空。</p><p><strong>上行遍历（父标签的名称为例）</strong></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token keyword">for</span> parent <span class="token keyword">in</span> soup<span class="token punctuation">.</span>a<span class="token punctuation">.</span>parent<span class="token punctuation">:</span>    <span class="token keyword">if</span> parent <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>parent<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>parent<span class="token punctuation">.</span>name<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h2 id="标签树的平行遍历"><a href="#标签树的平行遍历" class="headerlink" title="标签树的平行遍历"></a><strong>标签树的平行遍历</strong></h2><p><strong>平行遍历发生在同一个父节点下的各节点间。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmlbqst.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p><strong>上图中title与p不是平行遍历关系，而body下的p与p是平行关系。</strong></p><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.next_sibling</td><td align="left">返回按照HTML文本顺序的下一个平行节点标签</td></tr><tr><td align="left">.previous_sibling</td><td align="left">返回按照HTML文本顺序的上一个平行节点标签</td></tr><tr><td align="left">.next_siblings</td><td align="left">迭代类型，返回按照HTML文本顺序的后续所有平行节点标签</td></tr><tr><td align="left">.previous_siblings</td><td align="left">迭代类型，返回按照HTML文本顺序的前续所有平行节点标签</td></tr></tbody></table><p>平行遍历</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> sibling <span class="token keyword">in</span> tag<span class="token punctuation">.</span>previous_siblings<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>sibling<span class="token punctuation">)</span><span class="token keyword">for</span> sibling <span class="token keyword">in</span> tag<span class="token punctuation">.</span>next_siblings<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>sibling<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=19">参考资料</a></p><p><a href="https://mc-july.cn/2020/11/02/python-c-5">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Request库爬取实例</title>
      <link href="2020/10/28/python-c-3/"/>
      <url>2020/10/28/python-c-3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-cyIRUarh" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="26608077" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme=" #2F4F4F"    ></div><p>&nbsp;</p><p>本篇主要尝试对各类网站进行爬取练习。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/crawler-p-1.jpg" alt="Audits - Lighthouse" loading="lazy"></p><h1 id="京东某商品信息"><a href="#京东某商品信息" class="headerlink" title="京东某商品信息"></a><strong>京东某商品信息</strong></h1><pre class="language-htm" data-language="htm"><code class="language-htm">例如：https:&#x2F;&#x2F;item.jd.com&#x2F;100008667323.html</code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0'</span><span class="token punctuation">&#125;</span><span class="token comment">#浏览器身份标识</span>url <span class="token operator">=</span> <span class="token string">"https://item.jd.com/100008667323.html"</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>注：京东提供了页面编码utf-8，r.encoding与r.apparent_encoding一致。</p><p>如果不加user-agent，r.status_code依然为200，但返回结果为登录页面。</p><p><strong>因为京东对爬虫有一定的限制，如果程序中不写明user-agent，访问者默认为python的一个程序，从而访问出错。解决办法只需将程序模拟为浏览器<em>Mozilla/5.0</em>，即可正常访问。</strong></p><p>&nbsp;</p><h1 id="亚马逊某商品信息"><a href="#亚马逊某商品信息" class="headerlink" title="亚马逊某商品信息"></a><strong>亚马逊某商品信息</strong></h1><pre class="language-html" data-language="html"><code class="language-html">例如：https://www.amazon.cn/dp/B01HIUT4D8</code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0'</span><span class="token punctuation">&#125;</span>url <span class="token operator">=</span> <span class="token string">"https://www.amazon.cn/dp/B01HIUT4D8"</span>cookie <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>cookies<span class="token operator">=</span>cookie<span class="token punctuation">,</span>headers<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>与京东略有不同，需要将cookie写入，否则回应信息会显示被识别为机器人。</p><p>cookie即某些网站为了辨别用户身份，进行<a href="https://baike.baidu.com/item/Session/479100">Session</a>跟踪而储存在用户本地终端上的数据（通常经过加密）。</p><p>&nbsp;</p><h1 id="百度360搜索关键词提交"><a href="#百度360搜索关键词提交" class="headerlink" title="百度360搜索关键词提交"></a><strong>百度360搜索关键词提交</strong></h1><p><code>百度的关键词接口：http://www.baidu.com/s?wd=keyword</code></p><p><code>360的关键词接口：http://www.baidu.com/s?q=keyword</code></p><p>以百度为例，360一致。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'wd'</span><span class="token punctuation">:</span><span class="token string">'python'</span><span class="token punctuation">&#125;</span>url <span class="token operator">=</span> <span class="token string">"http://www.baidu.com/s"</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>params<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>第一个输出的是get获取的url链接，可以看到键值对已经附加到了原url之后。</p><p>第二个输出的是获取内容长度，内容过多就没有进行输出。（两年前还是30w，现在近60w）</p><p>&nbsp;</p><h1 id="网络图片的爬取和存储"><a href="#网络图片的爬取和存储" class="headerlink" title="网络图片的爬取和存储"></a><strong>网络图片的爬取和存储</strong></h1><p>网络图片链接的格式：</p><p><code>http://www.example.com/picture.jpg</code></p><p>国家地理：</p><p><code>http://www.nationalgeographic.com.cn</code></p><p>以国家地理为例，选择一个图片web页面：</p><p><code>http://www.ngchina.com.cn/photocontest2020/images/top.jpg</code></p><p>代码如下</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestspath <span class="token operator">=</span> <span class="token string">"D:/abc.jpg"</span>url <span class="token operator">=</span> <span class="token string">"http://www.ngchina.com.cn/photocontest2020/images/top.jpg"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>r<span class="token punctuation">.</span>content<span class="token punctuation">)</span>  <span class="token comment">#r.content为返回内容的二进制形式</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><p>但这种程序是不完善的，还需要考虑各种情况。</p><p>简单进行修饰一下</p><pre class="language-none"><code class="language-none">import requestsimport osroot &#x3D; &quot;D:&#x2F;&#x2F;pics&#x2F;&#x2F;&quot;url &#x3D; &quot;http:&#x2F;&#x2F;www.ngchina.com.cn&#x2F;photocontest2020&#x2F;images&#x2F;top.jpg&quot;path &#x3D; root + url.split(&#39;&#x2F;&#39;)[-1]try:    if not os.path.exists(root):        os.mkdir(root)    if not os.path.exists(path):        r &#x3D; requests.get(url)        with open(path, &#39;wb&#39;) as f:            f.write(r.content)            f.close()            print(&quot;文件保存成功&quot;)    else:        print(&quot;文件已存在&quot;)except:    pritnf(&quot;爬取失败&quot;)</code></pre><p>&nbsp;</p><h1 id="IP地址归属地的自动查询"><a href="#IP地址归属地的自动查询" class="headerlink" title="IP地址归属地的自动查询"></a><strong>IP地址归属地的自动查询</strong></h1><p>python没有关于ip归属地的库文件。我们可以通过ip138进行查询。</p><p><code>https://www.ip138.com/</code></p><p>通过搜索任意一个ip地址可以得知，该url形式为</p><p><code>https://www.ip138.com/iplookup.asp?ip=ipaddress&amp;action=2</code></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0'</span><span class="token punctuation">&#125;</span>url <span class="token operator">=</span> <span class="token string">"https://www.ip138.com/iplookup.asp?ip="</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url <span class="token operator">+</span> <span class="token string">'ip地址'</span> <span class="token operator">+</span> <span class="token string">'&amp;action=2'</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">[</span><span class="token number">1000</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>尽管该网站的robots协议备注允许所有爬虫爬取，但实际运行过程中，不伪装成浏览器是无法进行正常访问的。</p><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=13">参考资料</a></p><p><a href="https://mc-july.cn/2020/10/30/python-c-4">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Robots协议</title>
      <link href="2020/10/27/python-c-2/"/>
      <url>2020/10/27/python-c-2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-uytllzVH" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1340543218" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#00FA9A"    ></div><p>&nbsp;</p><p>本节介绍关于网络爬虫的一些使用规范，以及对网络爬虫的应对方法</p><h1 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a><strong>Robots协议</strong></h1><p>作用：<strong>网站告知</strong>网络爬虫哪些页面可以抓取，哪些不行。</p><p>形式：在网站根目录下的robots.txt文件。</p><p>以京东Robots协议为例：</p><p><a href="https://www.jd.com/robots.txt">https://www.jd.com/robots.txt</a></p><pre class="language-html" data-language="html"><code class="language-html">User-agent: *#对于任意user-agent，都应遵循以下协议Disallow: /?*#不允许访问以?开头的路径Disallow: /pop/*.html#不允许访问pop路径Disallow: /pinpai/*.html?*#不允许访问pinpai路径User-agent: EtaoSpider#不允许该爬虫爬取Disallow: / User-agent: HuihuiSpider#不允许该爬虫爬取Disallow: / User-agent: GwdangSpider#不允许该爬虫爬取Disallow: / User-agent: WochachaSpider#不允许该爬虫爬取Disallow: /</code></pre><p>（EtaoSpider是一淘的抓取工具）</p><p>好奇康了康淘宝的robots协议</p><pre class="language-html" data-language="html"><code class="language-html">User-agent: BaiduspiderDisallow: /User-agent: baiduspiderDisallow: /</code></pre><p>仅对百度爬虫作出了限制</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/taobaorobots.jpg" alt="Audits - Lighthouse" loading="lazy"><em>图为在百度引擎中搜索淘宝的结果</em></p><p>&nbsp;</p><h2 id="Robots协议的使用"><a href="#Robots协议的使用" class="headerlink" title="Robots协议的使用"></a><strong>Robots协议的使用</strong></h2><p>Robots协议是建议但非约束，网络爬虫可以不遵守，但存在法律风险。<del>从入门到入牢</del></p><ul><li>在爬虫文件中添加对robots.txt协议的识别</li><li>人工识别</li></ul><p>一种情况原则上可以不遵守robots协议，即<em>类人类行为</em>的爬虫。</p><p>&nbsp;</p><h1 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a><strong>网络爬虫的限制</strong></h1><p><strong>来源审查：判断User-Agent进行限制（技术方面）</strong></p><ul><li>检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问。</li></ul><p><strong>发布公告：Robots协议（道德方面）</strong></p><ul><li>告知所有爬虫网站的爬取策略，要求爬虫遵守。</li></ul><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=8">参考资料</a></p><p><a href="https://mc-july.cn/2020/10/28/python-c-3">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.Requests库入门</title>
      <link href="2020/10/26/python-c-1/"/>
      <url>2020/10/26/python-c-1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-RmieqbVq" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1418766731" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#3DF3F3"    ></div><p>&nbsp;</p><p>(｀・ω・´)记笔记方便复习。</p><h1 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a><strong>HTTP协议</strong></h1><p>超文本传输协议，是一个基于“请求与响应”模式的、无状态（两次请求间无关联）的应用层协议（高于TTP协议）。</p><p>采用URL作为定位网络资源的标识。</p><p>&nbsp;</p><h2 id="URL"><a href="#URL" class="headerlink" title="URL"></a><strong>URL</strong></h2><p>URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源。</p><p>URL格式 ”http:// host [:port] [path]“</p><ul><li><p>host：合法的Internet主机域名或IP地址</p></li><li><p>port：端口号，缺省端口为80</p></li><li><p>path：请求资源的路径</p></li></ul><p>&nbsp;</p><h2 id="HTTP协议对资源的操作"><a href="#HTTP协议对资源的操作" class="headerlink" title="HTTP协议对资源的操作"></a><strong>HTTP协议对资源的操作</strong></h2><table><thead><tr><th align="left">方法</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">GET</td><td align="left">请求<u>获取</u>URL位置的资源</td></tr><tr><td align="left">HEAD</td><td align="left">请求<u>获取</u>URL位置资源的响应消息报告，即<strong>获得该资源的头部信息</strong></td></tr><tr><td align="left">POST</td><td align="left">请求向URL位置的资源后<u><strong>附加</strong></u>新的数据</td></tr><tr><td align="left">PUT</td><td align="left">请求向URL位置<u>存储</u>一个资源，<strong>覆盖</strong>原URL位置的资源</td></tr><tr><td align="left">PATCH</td><td align="left">请求局部更新URL位置的资源，即<u>改变</u><strong>该处资源</strong>的部分内容</td></tr><tr><td align="left">DELETE</td><td align="left">请求删除URL位置存储的资源</td></tr></tbody></table><ul><li>资源较大时，可用HEAD获取头部信息</li><li>修改部分可用PATCH，节省网络带宽</li></ul><p>&nbsp;</p><h1 id="Requests库"><a href="#Requests库" class="headerlink" title="Requests库"></a><strong>Requests库</strong></h1><p>7种主要方法与上表一一对应，都通过调用Request库实现</p><p>以r = requests.get(url)为例，Request库包含Response与Request两个对象</p><p>&nbsp;</p><h2 id="Response对象的属性"><a href="#Response对象的属性" class="headerlink" title="Response对象的属性"></a><strong>Response对象的属性</strong></h2><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">r.status_code</td><td align="left">HTTP请求的返回状态，200表示连接成功，404表示失败</td></tr><tr><td align="left">r.text</td><td align="left">HTTP响应内容的字符串形式，即url对应的页面内容</td></tr><tr><td align="left">r.recoding</td><td align="left">从HTTP header中<strong>猜测</strong>的响应内容编码方式</td></tr><tr><td align="left">r.apparent_encoding</td><td align="left">从内容中<strong>分析</strong>出的响应内容编码方式（备选编码方式）</td></tr><tr><td align="left">r.content</td><td align="left">HTTP响应内容的二进制形式</td></tr></tbody></table><ul><li>encoding的编码方式是从HTTP header中的charset中获得的。若header中不存在charset，则认为编码为ISO-8859-1</li><li>apparent_encoding从内容分析可能出现的编码形式。<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestsr <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://www.baidu.com"</span><span class="token punctuation">)</span>r<span class="token punctuation">.</span>status_code<span class="token comment">#返回值200</span>r<span class="token punctuation">.</span>text<span class="token comment">#返回内容乱码</span>r<span class="token punctuation">.</span>encoding<span class="token comment">#返回编码'ISO-8859-1'</span>r<span class="token punctuation">.</span>apparent_encoding<span class="token comment">#返回'utf-8'编码</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span> <span class="token comment">#备选编码替换原编码</span>r<span class="token punctuation">.</span>text<span class="token comment">#返回内容不为乱码</span></code></pre></li></ul><p>&nbsp;</p><h2 id="Requests库主要方法"><a href="#Requests库主要方法" class="headerlink" title="Requests库主要方法"></a><strong>Requests库主要方法</strong></h2><p>requests.request(method, url, **kwargs)</p><p>method：请求方式，对应get/put/post等7种</p><p>url：拟获取页面的url链接</p><p>**kwargs：控制访问的参数，共13个</p><p>&nbsp;</p><h3 id="kwargs参数列表"><a href="#kwargs参数列表" class="headerlink" title="kwargs参数列表"></a><strong>kwargs参数列表</strong></h3><h4 id="params"><a href="#params" class="headerlink" title="params"></a><strong>params</strong></h4><p>字典或字节序列，作为参数增加到url中</p><p>eg：</p><pre class="language-python" data-language="python"><code class="language-python">kv <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span><span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> params<span class="token operator">=</span>kv<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>url<span class="token punctuation">)</span></code></pre><p><code>输出值http://python123.io/ws?key1=value1&amp;key2=value2</code></p><p>使得url中附加参数，服务器根据参数筛选资源返回</p><p>&nbsp;</p><h4 id="data"><a href="#data" class="headerlink" title="data"></a><strong>data</strong></h4><p>字典、字节序列或文件对象，作为Request的内容。向服务器提交资源时使用。</p><pre class="language-python" data-language="python"><code class="language-python">kv <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>kv<span class="token punctuation">)</span>body <span class="token operator">=</span> <span class="token string">'主体内容'</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>body<span class="token punctuation">)</span></code></pre><p>与params不同，不放入url链接中，放入url对应位置作为数据存储</p><p>&nbsp;</p><h4 id="json"><a href="#json" class="headerlink" title="json"></a><strong>json</strong></h4><p>JSON格式的数据，作为Request的内容</p><pre class="language-python" data-language="python"><code class="language-python">kv <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> json<span class="token operator">=</span>kv<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h4 id="headers"><a href="#headers" class="headerlink" title="headers"></a><strong>headers</strong></h4><p>字典，HTTP定制头</p><pre class="language-python" data-language="python"><code class="language-python">hd <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span> <span class="token string">'Chrome/10'</span><span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>hd<span class="token punctuation">)</span></code></pre><p>以Chrom/10作为user-agent向服务器发起访问</p><p>&nbsp;</p><h4 id="cookies"><a href="#cookies" class="headerlink" title="cookies"></a><strong>cookies</strong></h4><p>字典或CookieJar，Request中的cookie</p><p>&nbsp;</p><h4 id="auth"><a href="#auth" class="headerlink" title="auth"></a><strong>auth</strong></h4><p>元组，支持HTTP认证功能</p><p>&nbsp;</p><h4 id="files"><a href="#files" class="headerlink" title="files"></a><strong>files</strong></h4><p>字典类型，传输文件</p><pre class="language-python" data-language="python"><code class="language-python">fs <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'file'</span><span class="token punctuation">:</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data.xls'</span><span class="token punctuation">,</span><span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> files<span class="token operator">=</span>fs<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h4 id="timeout"><a href="#timeout" class="headerlink" title="timeout"></a><strong>timeout</strong></h4><p>设定超时时间，单位为s</p><pre class="language-python" data-language="python"><code class="language-python">r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'GET'</span><span class="token punctuation">,</span> <span class="token string">'http://www.baidu.com'</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span></code></pre><p>若超时无返回值，则会产生timeout异常</p><p>&nbsp;</p><h4 id="proxies"><a href="#proxies" class="headerlink" title="proxies"></a><strong>proxies</strong></h4><p>字典类型，设定访问代理服务器，可以增加登录认证</p><pre class="language-python" data-language="python"><code class="language-python">pxs <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'http'</span><span class="token punctuation">:</span> <span class="token string">'http://user:pass@10.10.10.1:1234'</span><span class="token comment">#用户名及密码设置</span>   <span class="token string">'https'</span><span class="token punctuation">:</span> <span class="token string">'http://user:pass@10.10.10.1:1234'</span> <span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'GET'</span><span class="token punctuation">,</span> <span class="token string">'http://www.baidu.com'</span><span class="token punctuation">,</span> proxies<span class="token operator">=</span>pxs<span class="token punctuation">)</span></code></pre><p>例中访问百度时的ip即为代理服务器地址，用以隐藏ip</p><p>&nbsp;</p><h4 id="allow-redirects"><a href="#allow-redirects" class="headerlink" title="allow_redirects"></a><strong>allow_redirects</strong></h4><p>重定向开关，默认为true</p><p>&nbsp;</p><h4 id="stream"><a href="#stream" class="headerlink" title="stream"></a><strong>stream</strong></h4><p>获取内容立即下载开关，默认为true</p><p>&nbsp;</p><h4 id="verify"><a href="#verify" class="headerlink" title="verify"></a><strong>verify</strong></h4><p>认证SSL证书开关，默认为true</p><p>&nbsp;</p><h4 id="cert"><a href="#cert" class="headerlink" title="cert"></a><strong>cert</strong></h4><p>本地SSL证书路径</p><p>&nbsp;</p><h3 id="get方法-常用"><a href="#get方法-常用" class="headerlink" title="get方法(常用)"></a><strong>get方法(常用)</strong></h3><p><code>r = requests.get(url,params=None,**kwargs)</code></p><ul><li><p>url：拟获取页面的url链接</p></li><li><p>params：url中的额外参数，字典或字节流格式，可选</p></li><li><p>**kwargs：12个控制访问的参数</p></li></ul><p>&nbsp;</p><h3 id="head方法-常用"><a href="#head方法-常用" class="headerlink" title="head方法(常用)"></a><strong>head方法(常用)</strong></h3><p><code>r = requests.head(url,**kwargs)</code></p><pre class="language-python" data-language="python"><code class="language-python">r <span class="token operator">=</span> requests<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/get'</span><span class="token punctuation">)</span>r<span class="token punctuation">.</span>headers<span class="token comment">#返回头部信息</span>r<span class="token punctuation">.</span>text<span class="token comment">#返回内容为空</span></code></pre><p>&nbsp;</p><h3 id="post方法"><a href="#post方法" class="headerlink" title="post方法"></a><strong>post方法</strong></h3><p><code>r = requests.post(url,json=None,**kwargs)</code></p><pre class="language-python" data-language="python"><code class="language-python">payload <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/post'</span><span class="token punctuation">,</span> data <span class="token operator">=</span> payload<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token comment">#当向URL post一个字典/键值对 默认存储在表单(post)</span><span class="token triple-quoted-string string">'''&#123; ···"form":&#123;"key2":"value2","key1":"value1"&#125;,&#125;'''</span>——————————————————————————————————————————————r <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/post'</span><span class="token punctuation">,</span> data <span class="token operator">=</span> ‘ABC’<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token comment">#post字符串 相应在data中</span><span class="token triple-quoted-string string">'''&#123; ···"data": "ABC""form":&#123;&#125;,&#125;'''</span></code></pre><p>&nbsp;</p><h3 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a><strong>put方法</strong></h3><p><code>r = requests.put(url,data=None,**kwargs)</code></p><pre class="language-python" data-language="python"><code class="language-python">payload <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/post'</span><span class="token punctuation">,</span> data <span class="token operator">=</span> payload<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token comment">#与post方法类似，覆盖掉原有数据</span><span class="token triple-quoted-string string">'''&#123; ···"form":&#123;"key2":"value2","key1":"value1"&#125;,&#125;'''</span></code></pre><p>&nbsp;</p><h3 id="patch方法"><a href="#patch方法" class="headerlink" title="patch方法"></a><strong>patch方法</strong></h3><p><code>r = requests.get(url,data=None,**kwargs)</code></p><p>&nbsp;</p><h3 id="delete方法"><a href="#delete方法" class="headerlink" title="delete方法"></a><strong>delete方法</strong></h3><p><code>r = requests.delete(url,**kwargs)</code><br>&nbsp;</p><h1 id="爬取网页通用代码框架"><a href="#爬取网页通用代码框架" class="headerlink" title="爬取网页通用代码框架"></a><strong>爬取网页通用代码框架</strong></h1><h2 id="几种常见的异常"><a href="#几种常见的异常" class="headerlink" title="几种常见的异常"></a><strong>几种常见的异常</strong></h2><table><thead><tr><th align="left">异常</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">requests.ConnectionError</td><td align="left">网络连接错误异常，如DNS查询失败、拒绝连接等</td></tr><tr><td align="left">requests.HTTPError</td><td align="left">HTTP错误异常</td></tr><tr><td align="left">requests.URLRequired</td><td align="left">URL缺失异常</td></tr><tr><td align="left">requests.TooMantRedirects</td><td align="left">超过最大重定向次数，产生重定向异常</td></tr><tr><td align="left">requests.ConnectTimeout</td><td align="left"><strong>连接</strong>远程服务器<strong>超时</strong>异常</td></tr><tr><td align="left">requests.Timeout</td><td align="left">请求<strong>URL超时</strong>，产生超时异常</td></tr></tbody></table><p><strong>r.rasis_for_status()</strong></p><p>如果不是200，产生异常requests.HTTPError</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">def</span> <span class="token function">getHTMLText</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>timeout<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>        r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>        r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding        <span class="token keyword">return</span> r<span class="token punctuation">.</span>text    <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">"产生异常"</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    url<span class="token operator">=</span><span class="token string">"http://www.baidu.com"</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>getHTMLText<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h2 id="爬虫规模"><a href="#爬虫规模" class="headerlink" title="爬虫规模"></a><strong>爬虫规模</strong></h2><p>爬取网页：小规模，数据量小，爬取速度不敏感。Requests库。</p><p>爬取网站：中规模，数据规模较大，爬取速度敏感。Scrapy库。</p><p>爬取全网：大规模，搜索引擎，爬取速度尤其关键。定制开发。</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v">参考资料</a></p><p><a href="https://mc-july.cn/2020/10/27/python-c-2">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bilibili安全挑战赛（1-5）</title>
      <link href="2020/10/24/bilibili-CTF(1-5)/"/>
      <url>2020/10/24/bilibili-CTF(1-5)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script><p><a href="https://www.bilibili.com/blackboard/activity-20201024.html"><strong>bilibili安全挑战赛</strong></a> </p><p><strong>关于网络安全方面的学习，入门尝试，浏览器为Firefox。</strong></p><p><strong>线上比赛一般以解题模式（Jeopardy）为主。</strong></p><h2 id="第一题：页面的背后是什么？"><a href="#第一题：页面的背后是什么？" class="headerlink" title="第一题：页面的背后是什么？"></a>第一题：页面的背后是什么？</h2><p>&emsp;<a href="http://45.113.201.36/index.html">http://45.113.201.36/index.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-11.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>  &emsp;&emsp;  第一题对网页元素审查即可。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-12.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第二题：-真正的秘密只有特殊的设备才能看到"><a href="#第二题：-真正的秘密只有特殊的设备才能看到" class="headerlink" title="第二题： 真正的秘密只有特殊的设备才能看到"></a>第二题： 真正的秘密只有特殊的设备才能看到</h2><p>&emsp;<a href="http://45.113.201.36/index.html">http://45.113.201.36/index.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-11.jpg" alt="Audits - Lighthouse" loading="lazy"><em>需要使用bilibili Security Browser浏览器访问～</em></p><p> &emsp;&emsp;   根据提供的信息，可知用户代理名称bilibili Security Browser</p><p>  &emsp;&emsp;  编辑User-Agent重发文件名为2的请求，即可得到data。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-22.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第三题：-密码是啥？"><a href="#第三题：-密码是啥？" class="headerlink" title="第三题： 密码是啥？"></a>第三题： 密码是啥？</h2><p>&emsp;<a href="http://45.113.201.36/login.html">http://45.113.201.36/login.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-31.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p> &emsp;&emsp;   账号：admin    密码：bilibili</p><p> &emsp;&emsp;   送分题 (゜-゜)つロ 干杯~</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第四题：-对不起，权限不足"><a href="#第四题：-对不起，权限不足" class="headerlink" title="第四题： 对不起，权限不足"></a>第四题： 对不起，权限不足</h2><p>&emsp;<a href="http://45.113.201.36/superadmin.html">http://45.113.201.36/superadmin.html</a></p><p>&emsp;&emsp;    元素审查得到信息</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-41.jpg" alt="Audits - Lighthouse" loading="lazy"></p><table><tr><td bgcolor=#DCDCDC>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;有些秘密只有超级管理员才能看见哦~</td></tr></table><p>&emsp;&emsp;    编辑superadmin文件，在cookie一行找到了md5加密的role：ee11cbb19052e40b07aac0ca060c23ee，解密后为user。</p><p>&emsp;    说明要将超级管理员加密后对应修改，首先尝试的是superadmin，但编辑重发后并没有得到data，又试了试计算机的超级&amp;emsp管理员     Administrator，得到响应。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-42.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第五题：-别人的秘密"><a href="#第五题：-别人的秘密" class="headerlink" title="第五题： 别人的秘密"></a>第五题： 别人的秘密</h2><p>&emsp;<a href="http://45.113.201.36/user.html">http://45.113.201.36/user.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-51.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&emsp;&emsp;只提供了一条有效文件，并且给出uid=100336889这一参数。</p><p>&emsp;&emsp;分析代码后没有得出有效信息，需要暴力破解。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-52.jpg" alt="Audits - Lighthouse" loading="lazy"></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">import</span> jsonuid <span class="token operator">=</span> <span class="token number">100336889</span>headers <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"Cookie"</span><span class="token punctuation">:</span> <span class="token string">"对应填入"</span><span class="token punctuation">,</span>    <span class="token string">"Referer"</span><span class="token punctuation">:</span> <span class="token string">"http://45.113.201.36/user.html"</span><span class="token punctuation">,</span>    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36"</span><span class="token punctuation">&#125;</span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    resp <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://45.113.201.36/api/ctf/5?uid="</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>uid<span class="token punctuation">)</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>uid<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>resp<span class="token punctuation">.</span>text<span class="token punctuation">)</span>    jsonobj <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>resp<span class="token punctuation">.</span>text<span class="token punctuation">)</span>    <span class="token keyword">if</span> jsonobj<span class="token punctuation">[</span><span class="token string">'code'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"找到你了！"</span><span class="token punctuation">)</span>        <span class="token keyword">break</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        uid <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">continue</span></code></pre><p>&emsp;&emsp;循环几十次后便可得到flag。</p>]]></content>
      
      
      <categories>
          
          <category> 网络安全技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> CTF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字体背景色</title>
      <link href="2020/10/23/%E8%83%8C%E6%99%AF%E8%89%B2/"/>
      <url>2020/10/23/%E8%83%8C%E6%99%AF%E8%89%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>]]></content>
      
      
      <categories>
          
          <category> 资料 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
