<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>4.BeautifulSoup库入门</title>
      <link href="2020/10/30/python-c-4/"/>
      <url>2020/10/30/python-c-4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-dZMygmRg" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1387601942" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="  #E6E6FA"    ></div><p>&nbsp;</p><p><strong>在学习之前了解一下，为什么要引入BeautifulSoup库？</strong>根据前三节的学习，我们已经可以做到从网站上爬取需要的内容，并且打印出来，但仅仅局限于打印这些html，无法有效利用。后续操作就需要用到Beautifulsoup，解析html代码或是sml文档。</p><h1 id="BeautifulSoup库"><a href="#BeautifulSoup库" class="headerlink" title="BeautifulSoup库"></a><strong>BeautifulSoup库</strong></h1><p><code>官网：https://www.crummy.com/software/BeautifulSoup/</code></p><details><summary>官方解释</summary>Beautiful Soup 提供一些简单的、python 式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。 Beautiful Soup 自动将输入文档转换为 Unicode 编码，输出文档转换为 utf-8 编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup 就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。 Beautiful Soup 已成为和 lxml、html6lib 一样出色的 python 解释器，为用户灵活地提供不同的解析策略或强劲的速度。</details><p>使用方法：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup<span class="token comment">#从bs4中引入一个类，即BeautifulSoup</span>soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span><span class="token string">'&lt;p>data&lt;/p>'</span><span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>soup2 <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"D://demo.html"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span></code></pre><p><strong>data为需要bs4解析的html信息(可以是r.text或是引入文件)</strong></p><p><strong>html.parser为解析器</strong></p><p>&nbsp;</p><h2 id="BeautifulSoup库的理解"><a href="#BeautifulSoup库的理解" class="headerlink" title="BeautifulSoup库的理解"></a><strong>BeautifulSoup库的理解</strong></h2><p>首先源文件，即从浏览器中<strong>查看网页源代码</strong>或是通过<strong>requests库get到的text文件</strong>类型都如下图一般，由一对尖括号构成的标签组织起来的，每一对尖括号形成一对标签，标签之间存在上下元关系，从而形成一个<strong>标签树</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmlbqs.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>标签树分析，例如</p><pre class="language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>title<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    ...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span></code></pre><ul><li><p>p：标签的Name，成对出现</p></li><li><p>class=”title”：属性Attributes（属性域），包含0个或多个属性，用以定义标签的特点，由键值对构成。</p></li></ul><p><strong>Beautiful Soup库即是解析、遍历、维护“标签树”的功能库，也称beautifulsoup4或者bs4</strong></p><p>标签树可经BeautifulSoup处理转换成BeautifulSoup类，通常认为html文档，标签树，BeautifulSoup类三者等价。</p><p>&nbsp;</p><h2 id="BeautifulSoup类的基本元素"><a href="#BeautifulSoup类的基本元素" class="headerlink" title="BeautifulSoup类的基本元素"></a><strong>BeautifulSoup类的基本元素</strong></h2><table><thead><tr><th align="left">基本元素</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">Tag</td><td align="left">标签，最基本的信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾</td></tr><tr><td align="left">Name</td><td align="left">标签的名字，<p>…</p>的名字是’p’，格式：<tag>.name</td></tr><tr><td align="left">Attributes</td><td align="left">标签的属性，字典形式组织，格式：<tag>.attrs</td></tr><tr><td align="left">NavigableString</td><td align="left">标签内非属性字符串，&lt;&gt;…&lt;/&gt;中的字符串，格式：<tag>.string</td></tr><tr><td align="left">Comment</td><td align="left">标签内字符串的注释部分，一种特殊的Comment类型</td></tr></tbody></table><p>标签获取方法，例如</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding<span class="token comment">#调整编码</span>soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token comment">#解析获取的html</span><span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>title<span class="token punctuation">)</span><span class="token comment">#输出title标签</span><span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>a<span class="token punctuation">)</span><span class="token comment">#输出a标签，即链接标签</span></code></pre><p>为了方便，我们可以令<strong>tag = soup.a</strong>。对tag进行上表变换，例如</p><pre class="language-html" data-language="html"><code class="language-html">tag = soup.atag.name#a标签的名称"a"tag.attrs['class']#a标签[class]属性tag.string#标签的字符串信息type（tag.attrs)#标签属性类型type（tag)#标签类型type（tag.comment)#注释类型</code></pre><p><strong>我们也可以通过tag.parent/child来查看其父/子标签，下文会讲</strong></p><p>对标签类型判断的时候，很有可能该标签含有一个类型不同的子标签，该标签同样被bs4的标签类覆盖。</p><p>&nbsp;</p><h2 id="prettify-方法"><a href="#prettify-方法" class="headerlink" title="prettify()方法"></a><strong>prettify()方法</strong></h2><p>辅助作用，在每一个标签后加入换行符’\n’，使得输出文本容易阅读。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span>tag <span class="token operator">=</span> soup<span class="token punctuation">.</span>a<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>prettify<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#标签树</span><span class="token keyword">print</span><span class="token punctuation">(</span>tag<span class="token punctuation">.</span>prettify<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#每个标签同样适用</span></code></pre><p>&nbsp;</p><h1 id="HTML内容遍历方法"><a href="#HTML内容遍历方法" class="headerlink" title="HTML内容遍历方法"></a><strong>HTML内容遍历方法</strong></h1><h2 id="HTML基本格式"><a href="#HTML基本格式" class="headerlink" title="HTML基本格式"></a>HTML基本格式</h2><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmljbgs.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>用树来表示：</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmlbqst.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>有三种遍历方式。</p><p>&nbsp;</p><h2 id="标签树的下行遍历"><a href="#标签树的下行遍历" class="headerlink" title="标签树的下行遍历"></a><strong>标签树的下行遍历</strong></h2><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.contents</td><td align="left">子节点的列表，将<tag>所有儿子节点存入列表</td></tr><tr><td align="left">.children</td><td align="left">子节点的迭代类型，与.contents类似，用于循环遍历儿子节点</td></tr><tr><td align="left">.descendants</td><td align="left">子孙节点的迭代类型，包含所有子孙节点，用于循环遍历</td></tr></tbody></table><p>使用方法如下</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>head<span class="token punctuation">.</span>contents<span class="token punctuation">)</span></code></pre><p>我们可以用len函数获取子节点的数量</p><p><code>len(soup.head.contents)</code></p><p>因返回值是列表类型，故可以用下标来获取相关元素</p><p><code>print(soup.head.contents[1])</code></p><p><strong>下行遍历</strong></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> child <span class="token keyword">in</span> soup<span class="token punctuation">.</span>body<span class="token punctuation">.</span>children<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>child<span class="token punctuation">)</span><span class="token keyword">for</span> child <span class="token keyword">in</span> soup<span class="token punctuation">.</span>body<span class="token punctuation">.</span>descendants<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>child<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h2 id="标签树的上行遍历"><a href="#标签树的上行遍历" class="headerlink" title="标签树的上行遍历"></a><strong>标签树的上行遍历</strong></h2><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.parent</td><td align="left">节点的父亲标签</td></tr><tr><td align="left">.parents</td><td align="left">节点先辈标签的迭代类型，用于循环遍历先辈节点</td></tr></tbody></table><p>使用方法与下行类似，唯一不同soup作为一个特殊标签，父标签为空。</p><p><strong>上行遍历（父标签的名称为例）</strong></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupurl <span class="token operator">=</span> <span class="token string">"https://www.baidu.com"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encodingsoup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span><span class="token keyword">for</span> parent <span class="token keyword">in</span> soup<span class="token punctuation">.</span>a<span class="token punctuation">.</span>parent<span class="token punctuation">:</span>    <span class="token keyword">if</span> parent <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>parent<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>parent<span class="token punctuation">.</span>name<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h2 id="标签树的平行遍历"><a href="#标签树的平行遍历" class="headerlink" title="标签树的平行遍历"></a><strong>标签树的平行遍历</strong></h2><p><strong>平行遍历发生在同一个父节点下的各节点间。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/htmlbqst.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p><strong>上图中title与p不是平行遍历关系，而body下的p与p是平行关系。</strong></p><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">.next_sibling</td><td align="left">返回按照HTML文本顺序的下一个平行节点标签</td></tr><tr><td align="left">.previous_sibling</td><td align="left">返回按照HTML文本顺序的上一个平行节点标签</td></tr><tr><td align="left">.next_siblings</td><td align="left">迭代类型，返回按照HTML文本顺序的后续所有平行节点标签</td></tr><tr><td align="left">.previous_siblings</td><td align="left">迭代类型，返回按照HTML文本顺序的前续所有平行节点标签</td></tr></tbody></table><p>平行遍历</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> sibling <span class="token keyword">in</span> tag<span class="token punctuation">.</span>previous_siblings<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>sibling<span class="token punctuation">)</span><span class="token keyword">for</span> sibling <span class="token keyword">in</span> tag<span class="token punctuation">.</span>next_siblings<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>sibling<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=19">参考资料</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Request库爬取实例</title>
      <link href="2020/10/28/python-c-3/"/>
      <url>2020/10/28/python-c-3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-yHFQWbFK" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="26608077" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme=" #2F4F4F"    ></div><p>&nbsp;</p><p>本篇主要尝试对各类网站进行爬取练习。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/crawler-p-1.jpg" alt="Audits - Lighthouse" loading="lazy"></p><h1 id="京东某商品信息"><a href="#京东某商品信息" class="headerlink" title="京东某商品信息"></a><strong>京东某商品信息</strong></h1><pre class="language-htm" data-language="htm"><code class="language-htm">例如：https:&#x2F;&#x2F;item.jd.com&#x2F;100008667323.html</code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0'</span><span class="token punctuation">&#125;</span><span class="token comment">#浏览器身份标识</span>url <span class="token operator">=</span> <span class="token string">"https://item.jd.com/100008667323.html"</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>注：京东提供了页面编码utf-8，r.encoding与r.apparent_encoding一致。</p><p>如果不加user-agent，r.status_code依然为200，但返回结果为登录页面。</p><p><strong>因为京东对爬虫有一定的限制，如果程序中不写明user-agent，访问者默认为python的一个程序，从而访问出错。解决办法只需将程序模拟为浏览器<em>Mozilla/5.0</em>，即可正常访问。</strong></p><p>&nbsp;</p><h1 id="亚马逊某商品信息"><a href="#亚马逊某商品信息" class="headerlink" title="亚马逊某商品信息"></a><strong>亚马逊某商品信息</strong></h1><pre class="language-html" data-language="html"><code class="language-html">例如：https://www.amazon.cn/dp/B01HIUT4D8</code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0'</span><span class="token punctuation">&#125;</span>url <span class="token operator">=</span> <span class="token string">"https://www.amazon.cn/dp/B01HIUT4D8"</span>cookie <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>cookies<span class="token operator">=</span>cookie<span class="token punctuation">,</span>headers<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>与京东略有不同，需要将cookie写入，否则回应信息会显示被识别为机器人。</p><p>cookie即某些网站为了辨别用户身份，进行<a href="https://baike.baidu.com/item/Session/479100">Session</a>跟踪而储存在用户本地终端上的数据（通常经过加密）。</p><p>&nbsp;</p><h1 id="百度360搜索关键词提交"><a href="#百度360搜索关键词提交" class="headerlink" title="百度360搜索关键词提交"></a><strong>百度360搜索关键词提交</strong></h1><p><code>百度的关键词接口：http://www.baidu.com/s?wd=keyword</code></p><p><code>360的关键词接口：http://www.baidu.com/s?q=keyword</code></p><p>以百度为例，360一致。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'wd'</span><span class="token punctuation">:</span><span class="token string">'python'</span><span class="token punctuation">&#125;</span>url <span class="token operator">=</span> <span class="token string">"http://www.baidu.com/s"</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>params<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>第一个输出的是get获取的url链接，可以看到键值对已经附加到了原url之后。</p><p>第二个输出的是获取内容长度，内容过多就没有进行输出。（两年前还是30w，现在近60w）</p><p>&nbsp;</p><h1 id="网络图片的爬取和存储"><a href="#网络图片的爬取和存储" class="headerlink" title="网络图片的爬取和存储"></a><strong>网络图片的爬取和存储</strong></h1><p>网络图片链接的格式：</p><p><code>http://www.example.com/picture.jpg</code></p><p>国家地理：</p><p><code>http://www.nationalgeographic.com.cn</code></p><p>以国家地理为例，选择一个图片web页面：</p><p><code>http://www.ngchina.com.cn/photocontest2020/images/top.jpg</code></p><p>代码如下</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestspath <span class="token operator">=</span> <span class="token string">"D:/abc.jpg"</span>url <span class="token operator">=</span> <span class="token string">"http://www.ngchina.com.cn/photocontest2020/images/top.jpg"</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>r<span class="token punctuation">.</span>content<span class="token punctuation">)</span>  <span class="token comment">#r.content为返回内容的二进制形式</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><p>但这种程序是不完善的，还需要考虑各种情况。</p><p>简单进行修饰一下</p><pre class="language-none"><code class="language-none">import requestsimport osroot &#x3D; &quot;D:&#x2F;&#x2F;pics&#x2F;&#x2F;&quot;url &#x3D; &quot;http:&#x2F;&#x2F;www.ngchina.com.cn&#x2F;photocontest2020&#x2F;images&#x2F;top.jpg&quot;path &#x3D; root + url.split(&#39;&#x2F;&#39;)[-1]try:    if not os.path.exists(root):        os.mkdir(root)    if not os.path.exists(path):        r &#x3D; requests.get(url)        with open(path, &#39;wb&#39;) as f:            f.write(r.content)            f.close()            print(&quot;文件保存成功&quot;)    else:        print(&quot;文件已存在&quot;)except:    pritnf(&quot;爬取失败&quot;)</code></pre><p>&nbsp;</p><h1 id="IP地址归属地的自动查询"><a href="#IP地址归属地的自动查询" class="headerlink" title="IP地址归属地的自动查询"></a><strong>IP地址归属地的自动查询</strong></h1><p>python没有关于ip归属地的库文件。我们可以通过ip138进行查询。</p><p><code>https://www.ip138.com/</code></p><p>通过搜索任意一个ip地址可以得知，该url形式为</p><p><code>https://www.ip138.com/iplookup.asp?ip=ipaddress&amp;action=2</code></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestskv <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0'</span><span class="token punctuation">&#125;</span>url <span class="token operator">=</span> <span class="token string">"https://www.ip138.com/iplookup.asp?ip="</span><span class="token keyword">try</span><span class="token punctuation">:</span>    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url <span class="token operator">+</span> <span class="token string">'ip地址'</span> <span class="token operator">+</span> <span class="token string">'&amp;action=2'</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>kv<span class="token punctuation">)</span>    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">[</span><span class="token number">1000</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>    pritnf<span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span></code></pre><p>尽管该网站的robots协议备注允许所有爬虫爬取，但实际运行过程中，不伪装成浏览器是无法进行正常访问的。</p><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=13">参考资料</a></p><p><a href="https://mc-july.cn/2020/10/26/python-c-4">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Robots协议</title>
      <link href="2020/10/27/python-c-2/"/>
      <url>2020/10/27/python-c-2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-HGpSqJiL" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1340543218" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#00FA9A"    ></div><p>&nbsp;</p><p>本节介绍关于网络爬虫的一些使用规范，以及对网络爬虫的应对方法</p><h1 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a><strong>Robots协议</strong></h1><p>作用：<strong>网站告知</strong>网络爬虫哪些页面可以抓取，哪些不行。</p><p>形式：在网站根目录下的robots.txt文件。</p><p>以京东Robots协议为例：</p><p><a href="https://www.jd.com/robots.txt">https://www.jd.com/robots.txt</a></p><pre class="language-html" data-language="html"><code class="language-html">User-agent: *#对于任意user-agent，都应遵循以下协议Disallow: /?*#不允许访问以?开头的路径Disallow: /pop/*.html#不允许访问pop路径Disallow: /pinpai/*.html?*#不允许访问pinpai路径User-agent: EtaoSpider#不允许该爬虫爬取Disallow: / User-agent: HuihuiSpider#不允许该爬虫爬取Disallow: / User-agent: GwdangSpider#不允许该爬虫爬取Disallow: / User-agent: WochachaSpider#不允许该爬虫爬取Disallow: /</code></pre><p>（EtaoSpider是一淘的抓取工具）</p><p>好奇康了康淘宝的robots协议</p><pre class="language-html" data-language="html"><code class="language-html">User-agent: BaiduspiderDisallow: /User-agent: baiduspiderDisallow: /</code></pre><p>仅对百度爬虫作出了限制</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/taobaorobots.jpg" alt="Audits - Lighthouse" loading="lazy"><em>图为在百度引擎中搜索淘宝的结果</em></p><p>&nbsp;</p><h2 id="Robots协议的使用"><a href="#Robots协议的使用" class="headerlink" title="Robots协议的使用"></a><strong>Robots协议的使用</strong></h2><p>Robots协议是建议但非约束，网络爬虫可以不遵守，但存在法律风险。<del>从入门到入牢</del></p><ul><li>在爬虫文件中添加对robots.txt协议的识别</li><li>人工识别</li></ul><p>一种情况原则上可以不遵守robots协议，即<em>类人类行为</em>的爬虫。</p><p>&nbsp;</p><h1 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a><strong>网络爬虫的限制</strong></h1><p><strong>来源审查：判断User-Agent进行限制（技术方面）</strong></p><ul><li>检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问。</li></ul><p><strong>发布公告：Robots协议（道德方面）</strong></p><ul><li>告知所有爬虫网站的爬取策略，要求爬虫遵守。</li></ul><p>&nbsp;</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v?p=8">参考资料</a></p><p><a href="https://mc-july.cn/2020/10/26/python-c-3">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.Requests库入门</title>
      <link href="2020/10/26/python-c-1/"/>
      <url>2020/10/26/python-c-1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-eAPRbXRI" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="1418766731" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#3DF3F3"    ></div><p>&nbsp;</p><p>(｀・ω・´)记笔记方便复习。</p><h1 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a><strong>HTTP协议</strong></h1><p>超文本传输协议，是一个基于“请求与响应”模式的、无状态（两次请求间无关联）的应用层协议（高于TTP协议）。</p><p>采用URL作为定位网络资源的标识。</p><p>&nbsp;</p><h2 id="URL"><a href="#URL" class="headerlink" title="URL"></a><strong>URL</strong></h2><p>URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源。</p><p>URL格式 ”http:// host [:port] [path]“</p><ul><li><p>host：合法的Internet主机域名或IP地址</p></li><li><p>port：端口号，缺省端口为80</p></li><li><p>path：请求资源的路径</p></li></ul><p>&nbsp;</p><h2 id="HTTP协议对资源的操作"><a href="#HTTP协议对资源的操作" class="headerlink" title="HTTP协议对资源的操作"></a><strong>HTTP协议对资源的操作</strong></h2><table><thead><tr><th align="left">方法</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">GET</td><td align="left">请求<u>获取</u>URL位置的资源</td></tr><tr><td align="left">HEAD</td><td align="left">请求<u>获取</u>URL位置资源的响应消息报告，即<strong>获得该资源的头部信息</strong></td></tr><tr><td align="left">POST</td><td align="left">请求向URL位置的资源后<u><strong>附加</strong></u>新的数据</td></tr><tr><td align="left">PUT</td><td align="left">请求向URL位置<u>存储</u>一个资源，<strong>覆盖</strong>原URL位置的资源</td></tr><tr><td align="left">PATCH</td><td align="left">请求局部更新URL位置的资源，即<u>改变</u><strong>该处资源</strong>的部分内容</td></tr><tr><td align="left">DELETE</td><td align="left">请求删除URL位置存储的资源</td></tr></tbody></table><ul><li>资源较大时，可用HEAD获取头部信息</li><li>修改部分可用PATCH，节省网络带宽</li></ul><p>&nbsp;</p><h1 id="Requests库"><a href="#Requests库" class="headerlink" title="Requests库"></a><strong>Requests库</strong></h1><p>7种主要方法与上表一一对应，都通过调用Request库实现</p><p>以r = requests.get(url)为例，Request库包含Response与Request两个对象</p><p>&nbsp;</p><h2 id="Response对象的属性"><a href="#Response对象的属性" class="headerlink" title="Response对象的属性"></a><strong>Response对象的属性</strong></h2><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">r.status_code</td><td align="left">HTTP请求的返回状态，200表示连接成功，404表示失败</td></tr><tr><td align="left">r.text</td><td align="left">HTTP响应内容的字符串形式，即url对应的页面内容</td></tr><tr><td align="left">r.recoding</td><td align="left">从HTTP header中<strong>猜测</strong>的响应内容编码方式</td></tr><tr><td align="left">r.apparent_encoding</td><td align="left">从内容中<strong>分析</strong>出的响应内容编码方式（备选编码方式）</td></tr><tr><td align="left">r.content</td><td align="left">HTTP响应内容的二进制形式</td></tr></tbody></table><ul><li>encoding的编码方式是从HTTP header中的charset中获得的。若header中不存在charset，则认为编码为ISO-8859-1</li><li>apparent_encoding从内容分析可能出现的编码形式。<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestsr <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://www.baidu.com"</span><span class="token punctuation">)</span>r<span class="token punctuation">.</span>status_code<span class="token comment">#返回值200</span>r<span class="token punctuation">.</span>text<span class="token comment">#返回内容乱码</span>r<span class="token punctuation">.</span>encoding<span class="token comment">#返回编码'ISO-8859-1'</span>r<span class="token punctuation">.</span>apparent_encoding<span class="token comment">#返回'utf-8'编码</span>r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span> <span class="token comment">#备选编码替换原编码</span>r<span class="token punctuation">.</span>text<span class="token comment">#返回内容不为乱码</span></code></pre></li></ul><p>&nbsp;</p><h2 id="Requests库主要方法"><a href="#Requests库主要方法" class="headerlink" title="Requests库主要方法"></a><strong>Requests库主要方法</strong></h2><p>requests.request(method, url, **kwargs)</p><p>method：请求方式，对应get/put/post等7种</p><p>url：拟获取页面的url链接</p><p>**kwargs：控制访问的参数，共13个</p><p>&nbsp;</p><h3 id="kwargs参数列表"><a href="#kwargs参数列表" class="headerlink" title="kwargs参数列表"></a><strong>kwargs参数列表</strong></h3><h4 id="params"><a href="#params" class="headerlink" title="params"></a><strong>params</strong></h4><p>字典或字节序列，作为参数增加到url中</p><p>eg：</p><pre class="language-python" data-language="python"><code class="language-python">kv <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span><span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> params<span class="token operator">=</span>kv<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>url<span class="token punctuation">)</span></code></pre><p><code>输出值http://python123.io/ws?key1=value1&amp;key2=value2</code></p><p>使得url中附加参数，服务器根据参数筛选资源返回</p><p>&nbsp;</p><h4 id="data"><a href="#data" class="headerlink" title="data"></a><strong>data</strong></h4><p>字典、字节序列或文件对象，作为Request的内容。向服务器提交资源时使用。</p><pre class="language-python" data-language="python"><code class="language-python">kv <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>kv<span class="token punctuation">)</span>body <span class="token operator">=</span> <span class="token string">'主体内容'</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>body<span class="token punctuation">)</span></code></pre><p>与params不同，不放入url链接中，放入url对应位置作为数据存储</p><p>&nbsp;</p><h4 id="json"><a href="#json" class="headerlink" title="json"></a><strong>json</strong></h4><p>JSON格式的数据，作为Request的内容</p><pre class="language-python" data-language="python"><code class="language-python">kv <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> json<span class="token operator">=</span>kv<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h4 id="headers"><a href="#headers" class="headerlink" title="headers"></a><strong>headers</strong></h4><p>字典，HTTP定制头</p><pre class="language-python" data-language="python"><code class="language-python">hd <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span> <span class="token string">'Chrome/10'</span><span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>hd<span class="token punctuation">)</span></code></pre><p>以Chrom/10作为user-agent向服务器发起访问</p><p>&nbsp;</p><h4 id="cookies"><a href="#cookies" class="headerlink" title="cookies"></a><strong>cookies</strong></h4><p>字典或CookieJar，Request中的cookie</p><p>&nbsp;</p><h4 id="auth"><a href="#auth" class="headerlink" title="auth"></a><strong>auth</strong></h4><p>元组，支持HTTP认证功能</p><p>&nbsp;</p><h4 id="files"><a href="#files" class="headerlink" title="files"></a><strong>files</strong></h4><p>字典类型，传输文件</p><pre class="language-python" data-language="python"><code class="language-python">fs <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'file'</span><span class="token punctuation">:</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data.xls'</span><span class="token punctuation">,</span><span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> <span class="token string">'http://python123.io/ws'</span><span class="token punctuation">,</span> files<span class="token operator">=</span>fs<span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h4 id="timeout"><a href="#timeout" class="headerlink" title="timeout"></a><strong>timeout</strong></h4><p>设定超时时间，单位为s</p><pre class="language-python" data-language="python"><code class="language-python">r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'GET'</span><span class="token punctuation">,</span> <span class="token string">'http://www.baidu.com'</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span></code></pre><p>若超时无返回值，则会产生timeout异常</p><p>&nbsp;</p><h4 id="proxies"><a href="#proxies" class="headerlink" title="proxies"></a><strong>proxies</strong></h4><p>字典类型，设定访问代理服务器，可以增加登录认证</p><pre class="language-python" data-language="python"><code class="language-python">pxs <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'http'</span><span class="token punctuation">:</span> <span class="token string">'http://user:pass@10.10.10.1:1234'</span><span class="token comment">#用户名及密码设置</span>   <span class="token string">'https'</span><span class="token punctuation">:</span> <span class="token string">'http://user:pass@10.10.10.1:1234'</span> <span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'GET'</span><span class="token punctuation">,</span> <span class="token string">'http://www.baidu.com'</span><span class="token punctuation">,</span> proxies<span class="token operator">=</span>pxs<span class="token punctuation">)</span></code></pre><p>例中访问百度时的ip即为代理服务器地址，用以隐藏ip</p><p>&nbsp;</p><h4 id="allow-redirects"><a href="#allow-redirects" class="headerlink" title="allow_redirects"></a><strong>allow_redirects</strong></h4><p>重定向开关，默认为true</p><p>&nbsp;</p><h4 id="stream"><a href="#stream" class="headerlink" title="stream"></a><strong>stream</strong></h4><p>获取内容立即下载开关，默认为true</p><p>&nbsp;</p><h4 id="verify"><a href="#verify" class="headerlink" title="verify"></a><strong>verify</strong></h4><p>认证SSL证书开关，默认为true</p><p>&nbsp;</p><h4 id="cert"><a href="#cert" class="headerlink" title="cert"></a><strong>cert</strong></h4><p>本地SSL证书路径</p><p>&nbsp;</p><h3 id="get方法-常用"><a href="#get方法-常用" class="headerlink" title="get方法(常用)"></a><strong>get方法(常用)</strong></h3><p><code>r = requests.get(url,params=None,**kwargs)</code></p><ul><li><p>url：拟获取页面的url链接</p></li><li><p>params：url中的额外参数，字典或字节流格式，可选</p></li><li><p>**kwargs：12个控制访问的参数</p></li></ul><p>&nbsp;</p><h3 id="head方法-常用"><a href="#head方法-常用" class="headerlink" title="head方法(常用)"></a><strong>head方法(常用)</strong></h3><p><code>r = requests.head(url,**kwargs)</code></p><pre class="language-python" data-language="python"><code class="language-python">r <span class="token operator">=</span> requests<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/get'</span><span class="token punctuation">)</span>r<span class="token punctuation">.</span>headers<span class="token comment">#返回头部信息</span>r<span class="token punctuation">.</span>text<span class="token comment">#返回内容为空</span></code></pre><p>&nbsp;</p><h3 id="post方法"><a href="#post方法" class="headerlink" title="post方法"></a><strong>post方法</strong></h3><p><code>r = requests.post(url,json=None,**kwargs)</code></p><pre class="language-python" data-language="python"><code class="language-python">payload <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/post'</span><span class="token punctuation">,</span> data <span class="token operator">=</span> payload<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token comment">#当向URL post一个字典/键值对 默认存储在表单(post)</span><span class="token triple-quoted-string string">'''&#123; ···"form":&#123;"key2":"value2","key1":"value1"&#125;,&#125;'''</span>——————————————————————————————————————————————r <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/post'</span><span class="token punctuation">,</span> data <span class="token operator">=</span> ‘ABC’<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token comment">#post字符串 相应在data中</span><span class="token triple-quoted-string string">'''&#123; ···"data": "ABC""form":&#123;&#125;,&#125;'''</span></code></pre><p>&nbsp;</p><h3 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a><strong>put方法</strong></h3><p><code>r = requests.put(url,data=None,**kwargs)</code></p><pre class="language-python" data-language="python"><code class="language-python">payload <span class="token operator">=</span> <span class="token punctuation">&#123;</span>‘key1<span class="token string">': '</span>value<span class="token string">', '</span>key2<span class="token string">': '</span>value2'<span class="token punctuation">&#125;</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">'http://httpbin.org/post'</span><span class="token punctuation">,</span> data <span class="token operator">=</span> payload<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token comment">#与post方法类似，覆盖掉原有数据</span><span class="token triple-quoted-string string">'''&#123; ···"form":&#123;"key2":"value2","key1":"value1"&#125;,&#125;'''</span></code></pre><p>&nbsp;</p><h3 id="patch方法"><a href="#patch方法" class="headerlink" title="patch方法"></a><strong>patch方法</strong></h3><p><code>r = requests.get(url,data=None,**kwargs)</code></p><p>&nbsp;</p><h3 id="delete方法"><a href="#delete方法" class="headerlink" title="delete方法"></a><strong>delete方法</strong></h3><p><code>r = requests.delete(url,**kwargs)</code><br>&nbsp;</p><h1 id="爬取网页通用代码框架"><a href="#爬取网页通用代码框架" class="headerlink" title="爬取网页通用代码框架"></a><strong>爬取网页通用代码框架</strong></h1><h2 id="几种常见的异常"><a href="#几种常见的异常" class="headerlink" title="几种常见的异常"></a><strong>几种常见的异常</strong></h2><table><thead><tr><th align="left">异常</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">requests.ConnectionError</td><td align="left">网络连接错误异常，如DNS查询失败、拒绝连接等</td></tr><tr><td align="left">requests.HTTPError</td><td align="left">HTTP错误异常</td></tr><tr><td align="left">requests.URLRequired</td><td align="left">URL缺失异常</td></tr><tr><td align="left">requests.TooMantRedirects</td><td align="left">超过最大重定向次数，产生重定向异常</td></tr><tr><td align="left">requests.ConnectTimeout</td><td align="left"><strong>连接</strong>远程服务器<strong>超时</strong>异常</td></tr><tr><td align="left">requests.Timeout</td><td align="left">请求<strong>URL超时</strong>，产生超时异常</td></tr></tbody></table><p><strong>r.rasis_for_status()</strong></p><p>如果不是200，产生异常requests.HTTPError</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">def</span> <span class="token function">getHTMLText</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>timeout<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>        r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>        r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding        <span class="token keyword">return</span> r<span class="token punctuation">.</span>text    <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">"产生异常"</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    url<span class="token operator">=</span><span class="token string">"http://www.baidu.com"</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>getHTMLText<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>&nbsp;</p><h2 id="爬虫规模"><a href="#爬虫规模" class="headerlink" title="爬虫规模"></a><strong>爬虫规模</strong></h2><p>爬取网页：小规模，数据量小，爬取速度不敏感。Requests库。</p><p>爬取网站：中规模，数据规模较大，爬取速度敏感。Scrapy库。</p><p>爬取全网：大规模，搜索引擎，爬取速度尤其关键。定制开发。</p><p><a href="https://www.bilibili.com/video/BV1qs411n79v">参考资料</a></p><p><a href="https://mc-july.cn/2020/10/26/python-c-2">下一章节</a></p>]]></content>
      
      
      <categories>
          
          <category> python爬虫学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bilibili安全挑战赛（1-5）</title>
      <link href="2020/10/24/bilibili-CTF(1-5)/"/>
      <url>2020/10/24/bilibili-CTF(1-5)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script><p><a href="https://www.bilibili.com/blackboard/activity-20201024.html"><strong>bilibili安全挑战赛</strong></a> </p><p><strong>关于网络安全方面的学习，入门尝试，浏览器为Firefox。</strong></p><p><strong>线上比赛一般以解题模式（Jeopardy）为主。</strong></p><h2 id="第一题：页面的背后是什么？"><a href="#第一题：页面的背后是什么？" class="headerlink" title="第一题：页面的背后是什么？"></a>第一题：页面的背后是什么？</h2><p>&emsp;<a href="http://45.113.201.36/index.html">http://45.113.201.36/index.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-11.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>  &emsp;&emsp;  第一题对网页元素审查即可。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-12.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第二题：-真正的秘密只有特殊的设备才能看到"><a href="#第二题：-真正的秘密只有特殊的设备才能看到" class="headerlink" title="第二题： 真正的秘密只有特殊的设备才能看到"></a>第二题： 真正的秘密只有特殊的设备才能看到</h2><p>&emsp;<a href="http://45.113.201.36/index.html">http://45.113.201.36/index.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-11.jpg" alt="Audits - Lighthouse" loading="lazy"><em>需要使用bilibili Security Browser浏览器访问～</em></p><p> &emsp;&emsp;   根据提供的信息，可知用户代理名称bilibili Security Browser</p><p>  &emsp;&emsp;  编辑User-Agent重发文件名为2的请求，即可得到data。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-22.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第三题：-密码是啥？"><a href="#第三题：-密码是啥？" class="headerlink" title="第三题： 密码是啥？"></a>第三题： 密码是啥？</h2><p>&emsp;<a href="http://45.113.201.36/login.html">http://45.113.201.36/login.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-31.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p> &emsp;&emsp;   账号：admin    密码：bilibili</p><p> &emsp;&emsp;   送分题 (゜-゜)つロ 干杯~</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第四题：-对不起，权限不足"><a href="#第四题：-对不起，权限不足" class="headerlink" title="第四题： 对不起，权限不足"></a>第四题： 对不起，权限不足</h2><p>&emsp;<a href="http://45.113.201.36/superadmin.html">http://45.113.201.36/superadmin.html</a></p><p>&emsp;&emsp;    元素审查得到信息</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-41.jpg" alt="Audits - Lighthouse" loading="lazy"></p><table><tr><td bgcolor=#DCDCDC>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;有些秘密只有超级管理员才能看见哦~</td></tr></table><p>&emsp;&emsp;    编辑superadmin文件，在cookie一行找到了md5加密的role：ee11cbb19052e40b07aac0ca060c23ee，解密后为user。</p><p>&emsp;    说明要将超级管理员加密后对应修改，首先尝试的是superadmin，但编辑重发后并没有得到data，又试了试计算机的超级&amp;emsp管理员     Administrator，得到响应。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-42.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2 id="第五题：-别人的秘密"><a href="#第五题：-别人的秘密" class="headerlink" title="第五题： 别人的秘密"></a>第五题： 别人的秘密</h2><p>&emsp;<a href="http://45.113.201.36/user.html">http://45.113.201.36/user.html</a></p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-51.jpg" alt="Audits - Lighthouse" loading="lazy"></p><p>&emsp;&emsp;只提供了一条有效文件，并且给出uid=100336889这一参数。</p><p>&emsp;&emsp;分析代码后没有得出有效信息，需要暴力破解。</p><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/bictf/bictf-52.jpg" alt="Audits - Lighthouse" loading="lazy"></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">import</span> jsonuid <span class="token operator">=</span> <span class="token number">100336889</span>headers <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"Cookie"</span><span class="token punctuation">:</span> <span class="token string">"对应填入"</span><span class="token punctuation">,</span>    <span class="token string">"Referer"</span><span class="token punctuation">:</span> <span class="token string">"http://45.113.201.36/user.html"</span><span class="token punctuation">,</span>    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36"</span><span class="token punctuation">&#125;</span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    resp <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://45.113.201.36/api/ctf/5?uid="</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>uid<span class="token punctuation">)</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>uid<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>resp<span class="token punctuation">.</span>text<span class="token punctuation">)</span>    jsonobj <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>resp<span class="token punctuation">.</span>text<span class="token punctuation">)</span>    <span class="token keyword">if</span> jsonobj<span class="token punctuation">[</span><span class="token string">'code'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"找到你了！"</span><span class="token punctuation">)</span>        <span class="token keyword">break</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        uid <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">continue</span></code></pre><p>&emsp;&emsp;循环几十次后便可得到flag。</p>]]></content>
      
      
      <categories>
          
          <category> 网络安全技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> CTF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字体背景色</title>
      <link href="2020/10/23/%E8%83%8C%E6%99%AF%E8%89%B2/"/>
      <url>2020/10/23/%E8%83%8C%E6%99%AF%E8%89%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>]]></content>
      
      
      <categories>
          
          <category> 资料 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>烟雨行舟</title>
      <link href="2020/10/21/music/"/>
      <url>2020/10/21/music/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js"></script>    <div id="aplayer-EhlSSndi" class="aplayer aplayer-tag-marker meting-tag-marker"         data-id="32922246" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#51535F"    ></div><p><img src="https://cdn.jsdelivr.net/gh/s1003063367/cdn/images/cover-yyxz.jpg" alt="Audits - Lighthouse" loading="lazy"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
